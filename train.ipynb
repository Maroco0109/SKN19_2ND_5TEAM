{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f904acd",
   "metadata": {},
   "source": [
    "### 모델 학습용 코드 구현 및 실행\n",
    "\n",
    "- 학습별 코드 분리 (구분선 사용 및 해당 모델 이름 작성)\n",
    "- 학습된 파라미터는 ./parameters 에 .pth 형식으로 저장하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e61870",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = ['./data/2022Data_part1.csv', './data/2022Data_part2.csv']\n",
    "\n",
    "### Colab 사용시 주석 제거\n",
    "\n",
    "# !rm -rf SKN19_2ND_5TEAM\n",
    "# !git clone https://github.com/SKNetworks-AI19-250818/SKN19_2ND_5TEAM.git\n",
    "# %cd SKN19_2ND_5TEAM\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/SKN19_2ND_5TEAM')\n",
    "# input_file_path = ['/content/SKN19_2ND_5TEAM/data/encoded_dataset.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6121bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import modules.DataAnalysis as DataAnalysis\n",
    "import modules.ModelAnalysis as ModelAnalysis\n",
    "import modules.DataModify as DataModify\n",
    "from modules.DataSelect import DataPreprocessing\n",
    "\n",
    "import modules.Models as Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9614b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d425e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SKN_19\\SKN19_2ND_5TEAM\\modules\\DataModify.py:446: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 시드 고정 : 결과 비교용\n",
    "Models.set_seed(42)\n",
    "\n",
    "dp = DataPreprocessing()\n",
    "\n",
    "# device 설정 (cuda 사용 가능 시 cuda 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset 로드\n",
    "dataset = DataModify.CancerDataset(\n",
    "    target_column='target_label',              # target column\n",
    "    time_column='Survival months_bin_3m',      # Survival months\n",
    "    file_paths=input_file_path,\n",
    "    transform=dp.run                           # 기존에 정제가 완료된 데이터를 사용할 경우 None\n",
    ")\n",
    "\n",
    "sui_input_file_path = ['./data/Suicide.csv']\n",
    "sui_dataset = DataModify.CancerDataset(\n",
    "    target_column='target_label',              # target column\n",
    "    time_column='Survival months_bin_3m',      # Survival months\n",
    "    file_paths=sui_input_file_path,\n",
    "    transform=dp.run                           # 기존에 정제가 완료된 데이터를 사용할 경우 None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b1b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set size 설정 및 분리\n",
    "# 전체 길이\n",
    "n = len(dataset)\n",
    "\n",
    "# 비율 설정\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# 각 세트 크기 계산\n",
    "train_size = int(n * train_ratio)\n",
    "val_size = int(n * val_ratio)\n",
    "test_size = n - train_size - val_size  # 합이 정확히 맞도록 조정\n",
    "\n",
    "# 분리 수행\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_dataset = ConcatDataset([train_dataset, sui_dataset])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 데이터를 로드\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "input_dim = dataset.data.shape[1]   # input dimension : data의 feature의 개수\n",
    "hidden_size = (128, 64)             # 1번째, 2번째 hidden layer의 size\n",
    "time_bins = 91                      # 3개월 단위로 time을 split하여 각 구간으로 삼음 -> 270개월+ 는 하나로 취급\n",
    "num_events = 4                      # 사건의 개수\n",
    "\n",
    "# 모델 선언\n",
    "model = Models.DeepHitSurvWithSEBlockCNN(input_dim, hidden_size, time_bins, num_events, dropout=.2).to(device)\n",
    "\n",
    "# 손실함수 및 optimizer 선언\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52867e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "def train_epoch(model, loader, optimizer, device=device):\n",
    "    # 모델을 train 모드로 설정\n",
    "    model.train()\n",
    "    # loss 변수 선언\n",
    "    total_loss, total_lik, total_rank = 0, 0, 0\n",
    "\n",
    "    # loader에서 불러온 데이터를 기반으로 학습\n",
    "    for x, times, events in loader:\n",
    "        x, times, events = x.to(device), times.to(device), events.to(device)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, pmf, cif = model(x)\n",
    "        loss, L_lik, L_rank = Models.deephit_loss(pmf, cif, times, events)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_lik += L_lik.item() * x.size(0)\n",
    "        total_rank += L_rank.item() * x.size(0)\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss/n, total_lik/n, total_rank/n\n",
    "\n",
    "# 모델 평가\n",
    "def evaluate(model, loader, device=device):\n",
    "    # 모델을 평가 모드로 설정\n",
    "    model.eval()\n",
    "    total_loss, total_lik, total_rank = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, times, events in loader:\n",
    "            x, times, events = x.to(device), times.to(device), events.to(device)\n",
    "\n",
    "            logits, pmf, cif = model(x)\n",
    "            loss, L_lik, L_rank = Models.deephit_loss(pmf, cif, times, events)\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_lik += L_lik.item() * x.size(0)\n",
    "            total_rank += L_rank.item() * x.size(0)\n",
    "\n",
    "    n = len(loader.dataset)\n",
    "    return total_loss/n, total_lik/n, total_rank/n\n",
    "\n",
    "def get_cif_from_model(model, loader, device=device):\n",
    "    model.eval()\n",
    "    all_cif = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in loader:\n",
    "            x = x.to(device)\n",
    "            logits, pmf, cif = model(x)\n",
    "            all_cif.append(cif.cpu())\n",
    "            all_times.append(times)\n",
    "            all_events.append(events)\n",
    "    all_cif = torch.cat(all_cif, dim=0)  # (num_samples, num_events, time_bins)\n",
    "    all_times = torch.cat(all_times, dim=0)\n",
    "    all_events = torch.cat(all_events, dim=0)\n",
    "    return all_cif, all_times, all_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce35d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] Train Loss=0.9121 (L=0.9027, R=0.0187) | Val Loss=0.7227 (L=0.7157, R=0.0138)\n",
      "[002] Train Loss=0.7550 (L=0.7474, R=0.0153) | Val Loss=0.7049 (L=0.6992, R=0.0114)\n",
      "[003] Train Loss=0.7414 (L=0.7340, R=0.0149) | Val Loss=0.6878 (L=0.6818, R=0.0120)\n",
      "[004] Train Loss=0.7368 (L=0.7294, R=0.0148) | Val Loss=0.6971 (L=0.6910, R=0.0122)\n",
      "[005] Train Loss=0.7319 (L=0.7245, R=0.0148) | Val Loss=0.6831 (L=0.6768, R=0.0127)\n",
      "[006] Train Loss=0.7280 (L=0.7207, R=0.0146) | Val Loss=0.6846 (L=0.6778, R=0.0137)\n",
      "[007] Train Loss=0.7263 (L=0.7190, R=0.0146) | Val Loss=0.6999 (L=0.6920, R=0.0158)\n",
      "[008] Train Loss=0.7242 (L=0.7170, R=0.0144) | Val Loss=0.6802 (L=0.6739, R=0.0126)\n",
      "[009] Train Loss=0.7227 (L=0.7155, R=0.0145) | Val Loss=0.6813 (L=0.6753, R=0.0120)\n",
      "[010] Train Loss=0.7219 (L=0.7147, R=0.0144) | Val Loss=0.6773 (L=0.6710, R=0.0128)\n",
      "[011] Train Loss=0.7200 (L=0.7128, R=0.0144) | Val Loss=0.6791 (L=0.6726, R=0.0130)\n",
      "[012] Train Loss=0.7201 (L=0.7130, R=0.0143) | Val Loss=0.6739 (L=0.6673, R=0.0132)\n",
      "[013] Train Loss=0.7191 (L=0.7120, R=0.0143) | Val Loss=0.6831 (L=0.6762, R=0.0137)\n",
      "[014] Train Loss=0.7184 (L=0.7113, R=0.0142) | Val Loss=0.6769 (L=0.6710, R=0.0118)\n",
      "[015] Train Loss=0.7179 (L=0.7108, R=0.0142) | Val Loss=0.6900 (L=0.6822, R=0.0157)\n",
      "[016] Train Loss=0.7163 (L=0.7092, R=0.0142) | Val Loss=0.6737 (L=0.6675, R=0.0125)\n",
      "[017] Train Loss=0.7174 (L=0.7102, R=0.0144) | Val Loss=0.6728 (L=0.6663, R=0.0130)\n",
      "[018] Train Loss=0.7167 (L=0.7096, R=0.0142) | Val Loss=0.6775 (L=0.6711, R=0.0129)\n",
      "[019] Train Loss=0.7163 (L=0.7091, R=0.0143) | Val Loss=0.6836 (L=0.6779, R=0.0113)\n",
      "[020] Train Loss=0.7162 (L=0.7091, R=0.0143) | Val Loss=0.6849 (L=0.6793, R=0.0113)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss, train_lik, train_rank = train_epoch(model, train_loader, optimizer)\n",
    "    val_loss, val_lik, val_rank = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"[{epoch:03d}] \"\n",
    "          f\"Train Loss={train_loss:.4f} (L={train_lik:.4f}, R={train_rank:.4f}) | \"\n",
    "          f\"Val Loss={val_loss:.4f} (L={val_lik:.4f}, R={val_rank:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba13781",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./data/parameters/deephit_model_feature_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44512d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepHitSurvWithSEBlock(\n",
       "  (se_block): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=17, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (se_block_event): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (shared): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (heads): ModuleList(\n",
       "    (0-3): 4 x Linear(in_features=64, out_features=91, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_params_path = './data/parameters/deephit_model_without_feature_concat.pth'\n",
    "\n",
    "input_dim = dataset.data.shape[1]   # input dimension : data의 feature의 개수\n",
    "hidden_size = (128, 64)             # 1번째, 2번째 hidden layer의 size\n",
    "time_bins = 91                     # 3개월 단위로 time을 split하여 각 구간으로 삼음 -> 최대 270개월 + 그 후\n",
    "num_events = 4                      # 사건의 개수\n",
    "\n",
    "# 모델 정의 (학습할 때 사용한 모델 클래스)\n",
    "model = Models.DeepHitSurvWithSEBlock(input_dim, \n",
    "                    hidden_size, \n",
    "                    time_bins, \n",
    "                    num_events,\n",
    "                    )  # 사건 수 맞게 설정\n",
    "model.load_state_dict(torch.load(input_params_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b26f5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set CIF 추출\n",
    "cif_train, times_train, events_train = get_cif_from_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d510be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_risk_score_sigmoid(pmf, time_lambda=0.05, event_weights=None):\n",
    "    \"\"\"\n",
    "    pmf: torch.Tensor, shape (B, E, T) - 사건별 시간 확률\n",
    "    time_lambda: float, 지수 감쇠 계수 (시간대 가중치)\n",
    "    event_weights: list or torch.Tensor, 길이 E, 사건별 가중치\n",
    "    \"\"\"\n",
    "    B, E, T = pmf.shape\n",
    "    device = pmf.device\n",
    "\n",
    "    # 시간 가중치\n",
    "    time_weights = torch.exp(-time_lambda * torch.arange(T, device=device))\n",
    "    \n",
    "    # 사건 가중치\n",
    "    if event_weights is None:\n",
    "        event_weights = torch.ones(E, device=device)\n",
    "    else:\n",
    "        event_weights = torch.tensor(event_weights, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 가중치 적용\n",
    "    weighted_pmf = pmf * time_weights.view(1, 1, T)\n",
    "    weighted_pmf = weighted_pmf * event_weights.view(1, E, 1)\n",
    "\n",
    "    # 가중합 계산\n",
    "    risk_score_raw = weighted_pmf.sum(dim=(1, 2))\n",
    "\n",
    "    # 0 기준으로 offset 제거 → 음수도 나오게\n",
    "    risk_score_raw = risk_score_raw - risk_score_raw.mean()\n",
    "\n",
    "    # 시그모이드 + 0~100 스케일\n",
    "    risk_score = torch.sigmoid(risk_score_raw) * 100\n",
    "\n",
    "    return risk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48265bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ 모델에서 PMF 추출\n",
    "def get_pmf_from_model(model, loader, device=device):\n",
    "    model.eval()\n",
    "    all_pmf = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in loader:\n",
    "            x = x.to(device)\n",
    "            logits, pmf, _ = model(x)  # CIF는 필요 없음\n",
    "\n",
    "            pmf = pmf[:, :, :-1]  # (batch_size, num_events, time_bins-1)\n",
    "            \n",
    "            all_pmf.append(pmf.cpu())\n",
    "            all_times.append(times)\n",
    "            all_events.append(events)\n",
    "    all_pmf = torch.cat(all_pmf, dim=0)  # (num_samples, num_events, time_bins)\n",
    "    all_times = torch.cat(all_times, dim=0)\n",
    "    all_events = torch.cat(all_events, dim=0)\n",
    "    return all_pmf, all_times, all_events\n",
    "\n",
    "# train set PMF 추출\n",
    "pmf_train, times_train, events_train = get_pmf_from_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f147eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대값: 99.99998\n",
      "최소값: 33.890053\n",
      "평균값: 48.777374\n",
      "앞 10개 값: [45.059364 58.211338 85.037155 68.17443  36.553883 39.81885  41.093353\n",
      " 60.54232  33.995552 38.352715]\n",
      "=== 라벨별 Risk Score 통계 ===\n",
      "\n",
      "Event -1:\n",
      "  개수: 366123\n",
      "  최대값: 99.9809\n",
      "  최소값: 33.8901\n",
      "  평균값: 46.5169\n",
      "\n",
      "Event 0:\n",
      "  개수: 41868\n",
      "  최대값: 99.9784\n",
      "  최소값: 33.9178\n",
      "  평균값: 67.2819\n",
      "\n",
      "Event 1:\n",
      "  개수: 5857\n",
      "  최대값: 99.7696\n",
      "  최소값: 33.9755\n",
      "  평균값: 52.1473\n",
      "\n",
      "Event 2:\n",
      "  개수: 6164\n",
      "  최대값: 99.9817\n",
      "  최소값: 34.1014\n",
      "  평균값: 50.9891\n",
      "\n",
      "Event 3:\n",
      "  개수: 2441\n",
      "  최대값: 100.0000\n",
      "  최소값: 34.0460\n",
      "  평균값: 56.7662\n"
     ]
    }
   ],
   "source": [
    "# 2️⃣ 사건별 가중치 설정\n",
    "event_weights = [2.0, 2.0, 1.0, 7.0]  # 예시\n",
    "\n",
    "# 3️⃣ 위험 점수 계산 (시그모이드 + 0~100)\n",
    "risk_scores = compute_risk_score_sigmoid(pmf_train, time_lambda=0.05, event_weights=event_weights).numpy()\n",
    "\n",
    "# 4️⃣ 통계 확인\n",
    "print(\"최대값:\", np.max(risk_scores))\n",
    "print(\"최소값:\", np.min(risk_scores))\n",
    "print(\"평균값:\", np.mean(risk_scores))\n",
    "print(\"앞 10개 값:\", risk_scores[:10])\n",
    "\n",
    "# 5️⃣ 사건별 통계\n",
    "events_np = events_train.numpy()\n",
    "unique_events = np.unique(events_np)\n",
    "\n",
    "print(\"=== 라벨별 Risk Score 통계 ===\")\n",
    "for e in unique_events:\n",
    "    mask = (events_np == e)\n",
    "    scores_e = risk_scores[mask]\n",
    "    if len(scores_e) == 0:\n",
    "        continue\n",
    "    print(f\"\\nEvent {e}:\")\n",
    "    print(f\"  개수: {len(scores_e)}\")\n",
    "    print(f\"  최대값: {np.max(scores_e):.4f}\")\n",
    "    print(f\"  최소값: {np.min(scores_e):.4f}\")\n",
    "    print(f\"  평균값: {np.mean(scores_e):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c63ed3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사건별 마지막 CIF를 입력으로 사용\n",
    "X_risk = cif_train[:, :, -2].numpy()  # (num_samples, num_events)\n",
    "weights = [0.3, 0.3, 1, 3]\n",
    "\n",
    "risk_target = np.zeros(X_risk.shape[0])\n",
    "for i in range(len(events_train)):\n",
    "    t_i = min(times_train[i], cif_train.shape[2]-2)  # 최대값 제한\n",
    "    if events_train[i] >= 0:\n",
    "        risk_target[i] = cif_train[i, events_train[i], t_i].item()\n",
    "    else:\n",
    "        risk_target[i] = cif_train[i, :, t_i].sum().item()  # 검열 처리\n",
    "\n",
    "risk_model = Models.WeightedCoxRiskEstimator(num_events=X_risk.shape[1], weights=weights, device=device)\n",
    "risk_model.fit(X_risk, times_train, events_train)\n",
    "\n",
    "torch.save(risk_model.event_linears.state_dict(), \"./data/parameters/risk_model_event_linears.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad3468fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대값: 99.85215\n",
      "최소값: 91.372025\n",
      "평균값: 98.28919\n",
      "앞 10개 값: [96.10712  99.62866  99.82557  97.37601  99.60299  99.56934  95.52262\n",
      " 95.01497  92.355606 99.58003 ]\n"
     ]
    }
   ],
   "source": [
    "risk_scores = risk_model.predict(X_risk)\n",
    "\n",
    "print(\"최대값:\", np.max(risk_scores))\n",
    "print(\"최소값:\", np.min(risk_scores))\n",
    "print(\"평균값:\", np.mean(risk_scores))\n",
    "print(\"앞 10개 값:\", risk_scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45b7562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 라벨별 Risk Score 통계 ===\n",
      "\n",
      "Event -1:\n",
      "  개수: 366123\n",
      "  최대값: 99.8521\n",
      "  최소값: 91.3720\n",
      "  평균값: 98.2895\n",
      "\n",
      "Event 0:\n",
      "  개수: 41868\n",
      "  최대값: 99.8504\n",
      "  최소값: 91.3720\n",
      "  평균값: 98.2888\n",
      "\n",
      "Event 1:\n",
      "  개수: 5857\n",
      "  최대값: 99.8485\n",
      "  최소값: 91.3720\n",
      "  평균값: 98.2733\n",
      "\n",
      "Event 2:\n",
      "  개수: 6164\n",
      "  최대값: 99.8503\n",
      "  최소값: 91.3721\n",
      "  평균값: 98.2948\n",
      "\n",
      "Event 3:\n",
      "  개수: 2441\n",
      "  최대값: 99.8482\n",
      "  최소값: 91.3975\n",
      "  평균값: 98.2797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tensor → numpy 변환\n",
    "events_np = events_train.numpy()\n",
    "\n",
    "# 사건 라벨 종류 (-1은 검열)\n",
    "unique_events = np.unique(events_np)\n",
    "\n",
    "print(\"=== 라벨별 Risk Score 통계 ===\")\n",
    "for e in unique_events:\n",
    "    mask = (events_np == e)\n",
    "    scores_e = risk_scores[mask]\n",
    "\n",
    "    if len(scores_e) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nEvent {e}:\")\n",
    "    print(f\"  개수: {len(scores_e)}\")\n",
    "    print(f\"  최대값: {np.max(scores_e):.4f}\")\n",
    "    print(f\"  최소값: {np.min(scores_e):.4f}\")\n",
    "    print(f\"  평균값: {np.mean(scores_e):.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
