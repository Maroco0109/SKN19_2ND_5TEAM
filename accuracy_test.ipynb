{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac8137a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install lifelines\n",
    "# ! pip install scikit-survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec59d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "from sksurv.util import Surv\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import modules.DataAnalysis as DataAnalysis\n",
    "import modules.ModelAnalysis as ModelAnalysis\n",
    "import modules.DataModify as DataModify\n",
    "from modules.DataSelect import DataPreprocessing\n",
    "\n",
    "import modules.Models as Models\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa6d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deephit(model, test_loader, y_train, y_test, device='cuda', threshold=0.9):\n",
    "    \"\"\"\n",
    "    DeepHit 모델 평가 함수\n",
    "    - C-index\n",
    "    - Integrated Brier Score (IBS)\n",
    "    - 예측 시간 평균 오차 (MAE)\n",
    "    \n",
    "    마지막 시간 bin은 dummy이므로 제거 후 계산\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_risk = []\n",
    "    all_surv = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "\n",
    "    pred_times_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in test_loader:\n",
    "            x = x.to(device)\n",
    "            _, pmf, cif = model(x)  # pmf, cif 반환 (B, num_events, time_bins)\n",
    "\n",
    "            # -----------------------------\n",
    "            # 마지막 더미 시간 bin 제거\n",
    "            # -----------------------------\n",
    "            pmf = pmf[:, :, :-1]       # (B, num_events, time_bins-1)\n",
    "            cif = cif[:, :, :-1]\n",
    "            survival = 1 - cif.sum(dim=1)  # (B, time_bins-1)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Risk score 계산\n",
    "            # -----------------------------\n",
    "            risk_score = pmf.sum(dim=(1, 2))  # (B,)\n",
    "\n",
    "            all_risk.append(risk_score.cpu())\n",
    "            all_surv.append(survival.cpu())\n",
    "            all_times.append(times.cpu())\n",
    "            all_events.append(events.cpu())\n",
    "\n",
    "            # -----------------------------\n",
    "            # 예측 시간 계산\n",
    "            # -----------------------------\n",
    "            pmf_np = pmf.cpu().numpy()  # (B, num_events, time_bins)\n",
    "            batch_size, num_events, time_bins = pmf_np.shape\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                surv_prob = 1.0\n",
    "                pred_time = None\n",
    "                for t in range(time_bins):\n",
    "                    surv_prob *= (1 - pmf_np[i, :, t].sum())\n",
    "                    if surv_prob <= threshold and pred_time is None:\n",
    "                        pred_time = t\n",
    "                if pred_time is None:\n",
    "                    pred_time = time_bins - 1\n",
    "                pred_times_list.append(pred_time)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tensor → NumPy 변환\n",
    "    # -----------------------------\n",
    "    risk_score = torch.cat(all_risk).numpy()\n",
    "    survival = torch.cat(all_surv).numpy()\n",
    "    times = torch.cat(all_times).numpy()\n",
    "    events = torch.cat(all_events).numpy()\n",
    "    pred_times = np.array(pred_times_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Concordance Index 계산\n",
    "    # -----------------------------\n",
    "    c_index = concordance_index(\n",
    "        event_times=times,\n",
    "        predicted_scores=-risk_score,\n",
    "        event_observed=events\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Integrated Brier Score 계산\n",
    "    # -----------------------------\n",
    "    y_test_surv = Surv.from_arrays(\n",
    "        event=events.astype(bool),\n",
    "        time=times.astype(float)\n",
    "    )\n",
    "    max_time = int(y_test_surv[\"time\"].max())\n",
    "    survival = survival[:, :max_time]\n",
    "    eval_times = np.arange(max_time)\n",
    "    ibs = integrated_brier_score(y_train, y_test_surv, survival, eval_times)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 평균 절대 예측 시간 오차 (MAE) 계산\n",
    "    # -----------------------------\n",
    "    mae = np.mean(np.abs(pred_times - times))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 결과 출력\n",
    "    # -----------------------------\n",
    "    print(f\"Concordance Index (C-index): {c_index:.4f}\")\n",
    "    print(f\"Integrated Brier Score (IBS): {ibs:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE) of predicted time: {mae:.4f}\")\n",
    "\n",
    "    return c_index, ibs, mae, pred_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f8ee9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "# CSV 읽기 + 첫 열 제거\n",
    "df = pd.read_csv('./data/test dataset.csv')\n",
    "df = df.drop(df.columns[0], axis=1)  # 첫 열 제거\n",
    "df.to_csv('./data/test dataset_fixed.csv', index=False)\n",
    "\n",
    "# Dataset 로드\n",
    "test_file = ['./data/test dataset_fixed.csv']\n",
    "test_dataset = DataModify.CancerDataset(\n",
    "    target_column='event',\n",
    "    time_column='time',\n",
    "    file_paths=test_file\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# IBS 계산용 Surv 형식 생성\n",
    "test_times = test_dataset.time.numpy()\n",
    "test_events = test_dataset.target.numpy()\n",
    "\n",
    "# y_test만 있으면 IBS 계산 시 train은 동일 형식 dummy로 전달 가능\n",
    "y_test = Surv.from_arrays(event=test_events.astype(bool),\n",
    "                          time=test_times.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd41b0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepHitSurvWithSEBlockAnd2DCNN(\n",
       "  (se_block): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=17, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (se_block_event): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (shared): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (heads): ModuleList(\n",
       "    (0-3): 4 x Linear(in_features=64, out_features=91, bias=True)\n",
       "  )\n",
       "  (conv2d_block): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(2, 5), stride=(1, 1), padding=(1, 2))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(8, 16, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_params_path = './parameters/deephit_model_2D_CNN_1014_ver3.pth'\n",
    "\n",
    "input_dim = 17   # input dimension : data의 feature의 개수\n",
    "hidden_size = (128, 64)             # 1번째, 2번째 hidden layer의 size\n",
    "time_bins = 91                     # 3개월 단위로 time을 split하여 각 구간으로 삼음 -> 270개월+ 는 하나로 취급\n",
    "num_events = 4                      # 사건의 개수\n",
    "\n",
    "model_cfg = {\n",
    "    'dropout': 0.25,\n",
    "    'se_ratio': 0.25,\n",
    "    'conv_channels': (8, 16),\n",
    "    'conv_kernel_sizes': ((2, 5), (2, 3)),\n",
    "    'conv_padding': ((1, 2), (0, 1)),\n",
    "    'use_conv_batchnorm': True,\n",
    "}\n",
    "\n",
    "# train.ipynb에서 저장한 모델과 동일한 구성으로 선언\n",
    "model = Models.DeepHitSurvWithSEBlockAnd2DCNN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    time_bins=time_bins,\n",
    "    num_events=num_events,\n",
    "    dropout=model_cfg['dropout'],\n",
    "    se_ratio=model_cfg['se_ratio'],\n",
    "    conv_channels=model_cfg['conv_channels'],\n",
    "    conv_kernel_sizes=model_cfg['conv_kernel_sizes'],\n",
    "    conv_padding=model_cfg['conv_padding'],\n",
    "    use_conv_batchnorm=model_cfg['use_conv_batchnorm'],\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(input_params_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b57847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index (C-index): 0.9144\n",
      "Integrated Brier Score (IBS): 0.1638\n",
      "Mean Absolute Error (MAE) of predicted time: 5.3622\n"
     ]
    }
   ],
   "source": [
    "y_train_dummy = y_test.copy()\n",
    "\n",
    "# 평가 실행\n",
    "c_index, ibs, mae, _ = evaluate_deephit(model, test_loader, y_train_dummy, y_test, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fd15dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대값: 84.73279\n",
      "최소값: 35.18455\n",
      "평균값: 49.876034\n",
      "앞 10개 값: [50.45203  54.432343 39.769382 54.45437  38.73148  47.003635 40.76567\n",
      " 71.87959  48.67657  53.57527 ]\n",
      "=== 라벨별 Risk Score 통계 ===\n",
      "\n",
      "Event -1:\n",
      "  개수: 45767\n",
      "  최대값: 84.7328\n",
      "  최소값: 35.1846\n",
      "  평균값: 48.4546\n",
      "\n",
      "Event 0:\n",
      "  개수: 5263\n",
      "  최대값: 76.9516\n",
      "  최소값: 35.3300\n",
      "  평균값: 61.9425\n",
      "\n",
      "Event 1:\n",
      "  개수: 697\n",
      "  최대값: 76.4515\n",
      "  최소값: 35.3300\n",
      "  평균값: 51.6136\n",
      "\n",
      "Event 2:\n",
      "  개수: 773\n",
      "  최대값: 76.9948\n",
      "  최소값: 35.3300\n",
      "  평균값: 50.2848\n",
      "\n",
      "Event 3:\n",
      "  개수: 15\n",
      "  최대값: 72.2346\n",
      "  최소값: 38.0037\n",
      "  평균값: 51.2175\n"
     ]
    }
   ],
   "source": [
    "def compute_risk_score_sigmoid(pmf, time_lambda=0.05, event_weights=None):\n",
    "    \"\"\"\n",
    "    pmf: torch.Tensor, shape (B, E, T) - 사건별 시간 확률\n",
    "    time_lambda: float, 지수 감쇠 계수 (시간대 가중치)\n",
    "    event_weights: list or torch.Tensor, 길이 E, 사건별 가중치\n",
    "    \"\"\"\n",
    "    B, E, T = pmf.shape\n",
    "    device = pmf.device\n",
    "\n",
    "    # 시간 가중치\n",
    "    time_weights = torch.exp(-time_lambda * torch.arange(T, device=device))\n",
    "    \n",
    "    # 사건 가중치\n",
    "    if event_weights is None:\n",
    "        event_weights = torch.ones(E, device=device)\n",
    "    else:\n",
    "        event_weights = torch.tensor(event_weights, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 가중치 적용\n",
    "    weighted_pmf = pmf * time_weights.view(1, 1, T)\n",
    "    weighted_pmf = weighted_pmf * event_weights.view(1, E, 1)\n",
    "\n",
    "    # 가중합 계산\n",
    "    risk_score_raw = weighted_pmf.sum(dim=(1, 2))\n",
    "\n",
    "    # 0 기준으로 offset 제거 → 음수도 나오게\n",
    "    risk_score_raw = risk_score_raw - risk_score_raw.mean()\n",
    "\n",
    "    # 시그모이드 + 0~100 스케일\n",
    "    risk_score = torch.sigmoid(risk_score_raw) * 100\n",
    "\n",
    "    return risk_score\n",
    "\n",
    "def get_pmf_from_model(model, loader, device=device):\n",
    "    model.eval()\n",
    "    all_pmf = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in loader:\n",
    "            x = x.to(device)\n",
    "            logits, pmf, _ = model(x)  # CIF는 필요 없음\n",
    "\n",
    "            pmf = pmf[:, :, :91]  # (batch_size, num_events, time_bins-1)\n",
    "            \n",
    "            all_pmf.append(pmf.cpu())\n",
    "            all_times.append(times)\n",
    "            all_events.append(events)\n",
    "    all_pmf = torch.cat(all_pmf, dim=0)  # (num_samples, num_events, time_bins)\n",
    "    all_times = torch.cat(all_times, dim=0)\n",
    "    all_events = torch.cat(all_events, dim=0)\n",
    "    return all_pmf, all_times, all_events\n",
    " \n",
    "# train set PMF 추출\n",
    "pmf_train, times_train, events_train = get_pmf_from_model(model, test_loader)\n",
    "\n",
    "# 사건별 가중치 설정\n",
    "event_weights = [2.0, 3.0, 3.0, 15.0]  # 예시\n",
    "\n",
    "# 위험 점수 계산 (시그모이드 + 0~100)\n",
    "risk_scores = compute_risk_score_sigmoid(pmf_train, time_lambda=0.05, event_weights=event_weights).numpy()\n",
    "\n",
    "# 통계 확인\n",
    "print(\"최대값:\", np.max(risk_scores))\n",
    "print(\"최소값:\", np.min(risk_scores))\n",
    "print(\"평균값:\", np.mean(risk_scores))\n",
    "print(\"앞 10개 값:\", risk_scores[:10])\n",
    "\n",
    "# 사건별 통계\n",
    "events_np = events_train.numpy()\n",
    "unique_events = np.unique(events_np)\n",
    "\n",
    "print(\"=== 라벨별 Risk Score 통계 ===\")\n",
    "for e in unique_events:\n",
    "    mask = (events_np == e)\n",
    "    scores_e = risk_scores[mask]\n",
    "    if len(scores_e) == 0:\n",
    "        continue\n",
    "    print(f\"\\nEvent {e}:\")\n",
    "    print(f\"  개수: {len(scores_e)}\")\n",
    "    print(f\"  최대값: {np.max(scores_e):.4f}\")\n",
    "    print(f\"  최소값: {np.min(scores_e):.4f}\")\n",
    "    print(f\"  평균값: {np.mean(scores_e):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e532d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
