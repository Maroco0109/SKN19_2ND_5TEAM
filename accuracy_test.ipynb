{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8137a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lifelines\n",
      "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from lifelines) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from lifelines) (1.13.1)\n",
      "Requirement already satisfied: pandas>=2.1 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from lifelines) (2.3.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from lifelines) (3.9.4)\n",
      "Collecting autograd>=1.5 (from lifelines)\n",
      "  Downloading autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting autograd-gamma>=0.3 (from lifelines)\n",
      "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting formulaic>=0.2.2 (from lifelines)\n",
      "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
      "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: narwhals>=1.17 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from formulaic>=0.2.2->lifelines) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from formulaic>=0.2.2->lifelines) (4.15.0)\n",
      "Collecting wrapt>=1.0 (from formulaic>=0.2.2->lifelines)\n",
      "  Downloading wrapt-1.17.3-cp39-cp39-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from matplotlib>=3.0->lifelines) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.0->lifelines) (3.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from pandas>=2.1->lifelines) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from pandas>=2.1->lifelines) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
      "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
      "Downloading autograd-1.8.0-py3-none-any.whl (51 kB)\n",
      "Downloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
      "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Downloading wrapt-1.17.3-cp39-cp39-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (81 kB)\n",
      "Building wheels for collected packages: autograd-gamma\n",
      "\u001b[33m  DEPRECATION: Building 'autograd-gamma' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'autograd-gamma'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for autograd-gamma (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4119 sha256=bf204b75ca95a487400b666ece41f70bb9aa0b206040d557460ff5ccb96c59af\n",
      "  Stored in directory: /home/maroco/.cache/pip/wheels/a8/03/64/8557323821d25118c3a2dc1646996f7a962a8970d4b7d22473\n",
      "Successfully built autograd-gamma\n",
      "Installing collected packages: wrapt, interface-meta, autograd, autograd-gamma, formulaic, lifelines\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [lifelines]/6\u001b[0m [lifelines]\n",
      "\u001b[1A\u001b[2KSuccessfully installed autograd-1.8.0 autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.0 wrapt-1.17.3\n",
      "Collecting scikit-survival\n",
      "  Downloading scikit_survival-0.23.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Collecting ecos (from scikit-survival)\n",
      "  Downloading ecos-2.0.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: joblib in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from scikit-survival) (1.5.2)\n",
      "Collecting numexpr (from scikit-survival)\n",
      "  Downloading numexpr-2.10.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from scikit-survival) (2.0.2)\n",
      "Collecting osqp!=0.6.0,!=0.6.1 (from scikit-survival)\n",
      "  Downloading osqp-1.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from scikit-survival) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from scikit-survival) (1.13.1)\n",
      "Collecting scikit-learn<1.6,>=1.4.0 (from scikit-survival)\n",
      "  Downloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from scikit-learn<1.6,>=1.4.0->scikit-survival) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival) (78.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from pandas>=1.4.0->scikit-survival) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from pandas>=1.4.0->scikit-survival) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->scikit-survival) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/maroco/miniconda3/envs/Team5/lib/python3.9/site-packages (from jinja2->osqp!=0.6.0,!=0.6.1->scikit-survival) (2.1.5)\n",
      "Downloading scikit_survival-0.23.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading osqp-1.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading ecos-2.0.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Downloading numexpr-2.10.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
      "Installing collected packages: numexpr, scikit-learn, osqp, ecos, scikit-survival\n",
      "\u001b[2K  Attempting uninstall: scikit-learn\n",
      "\u001b[2K    Found existing installation: scikit-learn 1.6.1\n",
      "\u001b[2K    Uninstalling scikit-learn-1.6.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K      Successfully uninstalled scikit-learn-1.6.1━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [scikit-learn]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [scikit-survival] [scikit-survival]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ecos-2.0.14 numexpr-2.10.2 osqp-1.0.4 scikit-learn-1.5.2 scikit-survival-0.23.1\n"
     ]
    }
   ],
   "source": [
    "! pip install lifelines\n",
    "! pip install scikit-survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec59d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "from sksurv.util import Surv\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import modules.DataAnalysis as DataAnalysis\n",
    "import modules.ModelAnalysis as ModelAnalysis\n",
    "import modules.DataModify as DataModify\n",
    "from modules.DataSelect import DataPreprocessing\n",
    "\n",
    "import modules.Models as Models\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa6d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_deephit(model, test_loader, y_train, y_test, device='cuda', threshold=0.9):\n",
    "    \"\"\"\n",
    "    DeepHit 모델 평가 함수\n",
    "    - C-index\n",
    "    - Integrated Brier Score (IBS)\n",
    "    - 예측 시간 평균 오차 (MAE)\n",
    "    \n",
    "    마지막 시간 bin은 dummy이므로 제거 후 계산\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_risk = []\n",
    "    all_surv = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "\n",
    "    pred_times_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in test_loader:\n",
    "            x = x.to(device)\n",
    "            _, pmf, cif = model(x)  # pmf, cif 반환 (B, num_events, time_bins)\n",
    "\n",
    "            # -----------------------------\n",
    "            # 마지막 더미 시간 bin 제거\n",
    "            # -----------------------------\n",
    "            pmf = pmf[:, :, :-1]       # (B, num_events, time_bins-1)\n",
    "            cif = cif[:, :, :-1]\n",
    "            survival = 1 - cif.sum(dim=1)  # (B, time_bins-1)\n",
    "\n",
    "            # -----------------------------\n",
    "            # Risk score 계산\n",
    "            # -----------------------------\n",
    "            risk_score = pmf.sum(dim=(1, 2))  # (B,)\n",
    "\n",
    "            all_risk.append(risk_score.cpu())\n",
    "            all_surv.append(survival.cpu())\n",
    "            all_times.append(times.cpu())\n",
    "            all_events.append(events.cpu())\n",
    "\n",
    "            # -----------------------------\n",
    "            # 예측 시간 계산\n",
    "            # -----------------------------\n",
    "            pmf_np = pmf.cpu().numpy()  # (B, num_events, time_bins)\n",
    "            batch_size, num_events, time_bins = pmf_np.shape\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                surv_prob = 1.0\n",
    "                pred_time = None\n",
    "                for t in range(time_bins):\n",
    "                    surv_prob *= (1 - pmf_np[i, :, t].sum())\n",
    "                    if surv_prob <= threshold and pred_time is None:\n",
    "                        pred_time = t\n",
    "                if pred_time is None:\n",
    "                    pred_time = time_bins - 1\n",
    "                pred_times_list.append(pred_time)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Tensor → NumPy 변환\n",
    "    # -----------------------------\n",
    "    risk_score = torch.cat(all_risk).numpy()\n",
    "    survival = torch.cat(all_surv).numpy()\n",
    "    times = torch.cat(all_times).numpy()\n",
    "    events = torch.cat(all_events).numpy()\n",
    "    pred_times = np.array(pred_times_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Concordance Index 계산\n",
    "    # -----------------------------\n",
    "    c_index = concordance_index(\n",
    "        event_times=times,\n",
    "        predicted_scores=-risk_score,\n",
    "        event_observed=events\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Integrated Brier Score 계산\n",
    "    # -----------------------------\n",
    "    y_test_surv = Surv.from_arrays(\n",
    "        event=events.astype(bool),\n",
    "        time=times.astype(float)\n",
    "    )\n",
    "    max_time = int(y_test_surv[\"time\"].max())\n",
    "    survival = survival[:, :max_time]\n",
    "    eval_times = np.arange(max_time)\n",
    "    ibs = integrated_brier_score(y_train, y_test_surv, survival, eval_times)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 평균 절대 예측 시간 오차 (MAE) 계산\n",
    "    # -----------------------------\n",
    "    mae = np.mean(np.abs(pred_times - times))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 결과 출력\n",
    "    # -----------------------------\n",
    "    print(f\"Concordance Index (C-index): {c_index:.4f}\")\n",
    "    print(f\"Integrated Brier Score (IBS): {ibs:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE) of predicted time: {mae:.4f}\")\n",
    "\n",
    "    return c_index, ibs, mae, pred_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8ee9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "# CSV 읽기 + 첫 열 제거\n",
    "df = pd.read_csv('./data/test dataset.csv')\n",
    "df = df.drop(df.columns[0], axis=1)  # 첫 열 제거\n",
    "df.to_csv('./data/test dataset_fixed.csv', index=False)\n",
    "\n",
    "# Dataset 로드\n",
    "test_file = ['./data/test dataset_fixed.csv']\n",
    "test_dataset = DataModify.CancerDataset(\n",
    "    target_column='event',\n",
    "    time_column='time',\n",
    "    file_paths=test_file\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# IBS 계산용 Surv 형식 생성\n",
    "test_times = test_dataset.time.numpy()\n",
    "test_events = test_dataset.target.numpy()\n",
    "\n",
    "# y_test만 있으면 IBS 계산 시 train은 동일 형식 dummy로 전달 가능\n",
    "y_test = Surv.from_arrays(event=test_events.astype(bool),\n",
    "                          time=test_times.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd41b0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepHitSurvWithSEBlockAnd2DCNN(\n",
       "  (se_block): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=4, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=4, out_features=17, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (se_block_event): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=128, bias=True)\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (shared): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (heads): ModuleList(\n",
       "    (0-3): 4 x Linear(in_features=128, out_features=91, bias=True)\n",
       "  )\n",
       "  (conv2d_block): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(2, 5), stride=(1, 1), padding=(1, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(8, 16, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_params_path = './parameters/deephit_model_2D_CNN_1014.pth'\n",
    "\n",
    "input_dim = 17   # input dimension : data의 feature의 개수\n",
    "# hidden_size = (128, 64)             # 1번째, 2번째 hidden layer의 size\n",
    "hidden_size = (256, 128)             # 1번째, 2번째 hidden layer의 size\n",
    "time_bins = 91                     # 3개월 단위로 time을 split하여 각 구간으로 삼음 -> 270개월+ 는 하나로 취급\n",
    "num_events = 4                      # 사건의 개수\n",
    "\n",
    "# 모델 선언\n",
    "model = Models.DeepHitSurvWithSEBlockAnd2DCNN(input_dim, hidden_size, time_bins, num_events, dropout=.2).to(device)\n",
    "model.load_state_dict(torch.load(input_params_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b57847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concordance Index (C-index): 0.5922\n",
      "Integrated Brier Score (IBS): 0.2070\n",
      "Mean Absolute Error (MAE) of predicted time: 4.8093\n"
     ]
    }
   ],
   "source": [
    "y_train_dummy = y_test.copy()\n",
    "\n",
    "# 평가 실행\n",
    "c_index, ibs, mae, _ = evaluate_deephit(model, test_loader, y_train_dummy, y_test, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd15dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대값: 99.87458\n",
      "최소값: 37.199795\n",
      "평균값: 49.748444\n",
      "앞 10개 값: [42.03793  45.658817 41.58131  56.942047 45.706715 40.974632 44.850193\n",
      " 73.60887  43.248863 43.545296]\n",
      "=== 라벨별 Risk Score 통계 ===\n",
      "\n",
      "Event -1:\n",
      "  개수: 45767\n",
      "  최대값: 99.8719\n",
      "  최소값: 37.1998\n",
      "  평균값: 48.1044\n",
      "\n",
      "Event 0:\n",
      "  개수: 5263\n",
      "  최대값: 79.9476\n",
      "  최소값: 37.1998\n",
      "  평균값: 63.3496\n",
      "\n",
      "Event 1:\n",
      "  개수: 697\n",
      "  최대값: 77.2517\n",
      "  최소값: 37.1998\n",
      "  평균값: 52.9430\n",
      "\n",
      "Event 2:\n",
      "  개수: 773\n",
      "  최대값: 99.8746\n",
      "  최소값: 37.1998\n",
      "  평균값: 51.5281\n",
      "\n",
      "Event 3:\n",
      "  개수: 15\n",
      "  최대값: 74.9846\n",
      "  최소값: 40.8126\n",
      "  평균값: 53.5220\n"
     ]
    }
   ],
   "source": [
    "def compute_risk_score_sigmoid(pmf, time_lambda=0.05, event_weights=None):\n",
    "    \"\"\"\n",
    "    pmf: torch.Tensor, shape (B, E, T) - 사건별 시간 확률\n",
    "    time_lambda: float, 지수 감쇠 계수 (시간대 가중치)\n",
    "    event_weights: list or torch.Tensor, 길이 E, 사건별 가중치\n",
    "    \"\"\"\n",
    "    B, E, T = pmf.shape\n",
    "    device = pmf.device\n",
    "\n",
    "    # 시간 가중치\n",
    "    time_weights = torch.exp(-time_lambda * torch.arange(T, device=device))\n",
    "    \n",
    "    # 사건 가중치\n",
    "    if event_weights is None:\n",
    "        event_weights = torch.ones(E, device=device)\n",
    "    else:\n",
    "        event_weights = torch.tensor(event_weights, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 가중치 적용\n",
    "    weighted_pmf = pmf * time_weights.view(1, 1, T)\n",
    "    weighted_pmf = weighted_pmf * event_weights.view(1, E, 1)\n",
    "\n",
    "    # 가중합 계산\n",
    "    risk_score_raw = weighted_pmf.sum(dim=(1, 2))\n",
    "\n",
    "    # 0 기준으로 offset 제거 → 음수도 나오게\n",
    "    risk_score_raw = risk_score_raw - risk_score_raw.mean()\n",
    "\n",
    "    # 시그모이드 + 0~100 스케일\n",
    "    risk_score = torch.sigmoid(risk_score_raw) * 100\n",
    "\n",
    "    return risk_score\n",
    "\n",
    "def get_pmf_from_model(model, loader, device=device):\n",
    "    model.eval()\n",
    "    all_pmf = []\n",
    "    all_times = []\n",
    "    all_events = []\n",
    "    with torch.no_grad():\n",
    "        for x, times, events in loader:\n",
    "            x = x.to(device)\n",
    "            logits, pmf, _ = model(x)  # CIF는 필요 없음\n",
    "\n",
    "            pmf = pmf[:, :, :91]  # (batch_size, num_events, time_bins-1)\n",
    "            \n",
    "            all_pmf.append(pmf.cpu())\n",
    "            all_times.append(times)\n",
    "            all_events.append(events)\n",
    "    all_pmf = torch.cat(all_pmf, dim=0)  # (num_samples, num_events, time_bins)\n",
    "    all_times = torch.cat(all_times, dim=0)\n",
    "    all_events = torch.cat(all_events, dim=0)\n",
    "    return all_pmf, all_times, all_events\n",
    " \n",
    "# train set PMF 추출\n",
    "pmf_train, times_train, events_train = get_pmf_from_model(model, test_loader)\n",
    "\n",
    "# 사건별 가중치 설정\n",
    "event_weights = [2.0, 3.0, 3.0, 15.0]  # 예시\n",
    "\n",
    "# 위험 점수 계산 (시그모이드 + 0~100)\n",
    "risk_scores = compute_risk_score_sigmoid(pmf_train, time_lambda=0.05, event_weights=event_weights).numpy()\n",
    "\n",
    "# 통계 확인\n",
    "print(\"최대값:\", np.max(risk_scores))\n",
    "print(\"최소값:\", np.min(risk_scores))\n",
    "print(\"평균값:\", np.mean(risk_scores))\n",
    "print(\"앞 10개 값:\", risk_scores[:10])\n",
    "\n",
    "# 사건별 통계\n",
    "events_np = events_train.numpy()\n",
    "unique_events = np.unique(events_np)\n",
    "\n",
    "print(\"=== 라벨별 Risk Score 통계 ===\")\n",
    "for e in unique_events:\n",
    "    mask = (events_np == e)\n",
    "    scores_e = risk_scores[mask]\n",
    "    if len(scores_e) == 0:\n",
    "        continue\n",
    "    print(f\"\\nEvent {e}:\")\n",
    "    print(f\"  개수: {len(scores_e)}\")\n",
    "    print(f\"  최대값: {np.max(scores_e):.4f}\")\n",
    "    print(f\"  최소값: {np.min(scores_e):.4f}\")\n",
    "    print(f\"  평균값: {np.mean(scores_e):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e532d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
