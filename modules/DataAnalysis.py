"""

ë°ì´í„° ì‹œê°í™” ëª¨ë“ˆ

- ëª¨ë“  ë°ì´í„° ì‹œê°í™” ì½”ë“œë¥¼ í•¨ìˆ˜ë¡œ êµ¬í˜„
- ëª¨ë“  í•¨ìˆ˜ëŠ” ë¶„ì„í•  ë°ì´í„°ë¥¼ df í˜•íƒœë¡œ ë°›ìŒ
- ê¸°ë³¸ì ìœ¼ë¡œëŠ” return ê°’ì´ ì—†ëŠ” í•¨ìˆ˜. í•„ìš”ì— ë”°ë¼ ëª‡ëª‡ ë°ì´í„°ë¥¼ df í˜•íƒœë¡œ return

"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib as mpl
import matplotlib.cm as cm
from pathlib import Path

from IPython.display import display 

import modules.DataModify as DataModify

# ë°ì´í„° í”„ë ˆì„ì—ì„œ, ë²”ì£¼í˜• ë°ì´í„°ì— ì†í•˜ëŠ” ê°’ë“¤ì˜ ì»¬ëŸ¼ê°’ì„ ì¶œë ¥
def show_value_counts(df, cols=None, boundary=30) :
    for col in df.columns:
        if df[col].nunique(dropna=True) > boundary :  # ê°ê¸° ë‹¤ë¥¸ ê°’ì´ boundary ì´ìƒì¸ Continuous í•œ ê°’ë“¤ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ
            print(col)
            print('continuous')
            print("-"*20)
            continue

        series = df[col]
        if pd.api.types.is_extension_array_dtype(series.dtype):  # Nullable dtypes (e.g., Int64) need object conversion
            series = series.astype('object')
        value_counts = series.fillna("NA").value_counts(dropna=False)  # ê²°ì¸¡ì¹˜ëŠ” NAë¡œ ì²˜ë¦¬ í›„ ì¶œë ¥
        print(value_counts)
        print("-" * 20)

# EDA

def _set_style():
    # ì‹œê°í™” ê³µí†µ ìŠ¤íƒ€ì¼ ì„¤ì •: seaborn í…Œë§ˆ, í•œê¸€ í°íŠ¸, ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ í‘œì‹œ
    sns.set_theme(style="whitegrid", palette="crest")
    try:
        plt.rc('font', family='NanumGothic')
    except Exception:
        ...
    plt.rc('axes', unicode_minus=False)


def _load_encoded_data(df=None):
    # ë°ì´í„° ë¡œë”©: ì¸ìê°€ ì£¼ì–´ì§€ë©´ í•´ë‹¹ df ì‚¬ìš©, ì•„ë‹ˆë©´ ì¸ì½”ë”©ëœ CSV ë¡œë”©
    # - ë©”ì¸: data/encoded_dataset.csv
    # - COD í™•ì¥: data/EDA/encoded_dataset_COD.csv (ì—†ìœ¼ë©´ ë©”ì¸ìœ¼ë¡œ ëŒ€ì²´)
    if isinstance(df, pd.DataFrame) and not df.empty:
        return df.copy(), df.copy()

    def _find(rel):
        # ë‹¤ì–‘í•œ ê¸°ì¤€ ê²½ë¡œì—ì„œ íŒŒì¼ íƒìƒ‰: CWD, CWDì˜ ìƒìœ„, ë¦¬í¬ì§€í† ë¦¬ ë£¨íŠ¸(ëª¨ë“ˆ ê¸°ì¤€)
        candidates = []
        cwd = Path.cwd()
        candidates.append(cwd)
        candidates.append(cwd.parent)
        try:
            repo_root = Path(__file__).resolve().parents[1]
            candidates.append(repo_root)
        except Exception:
            pass
        # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
        seen = set()
        uniq = []
        for b in candidates:
            if b not in seen:
                uniq.append(b); seen.add(b)
        for base in uniq:
            p = base / rel
            if p.exists():
                return p
        return None

    p_main = _find(Path('data/encoded_dataset.csv'))
    p_cod = _find(Path('data/EDA/encoded_dataset_COD.csv'))
    enc = pd.read_csv(p_main) if p_main and p_main.exists() else None
    enc_cod = pd.read_csv(p_cod) if p_cod and p_cod.exists() else enc
    if enc is None:
        hint = f"searched at: {Path.cwd()/'data/encoded_dataset.csv'}, {(Path.cwd().parent)/'data/encoded_dataset.csv'}"
        raise FileNotFoundError('encoded_dataset.csv not found and no DataFrame provided\n' + hint)
    return enc, enc_cod

def _load_decoding_maps_from_md(md_candidates=None):
    # encoded_label.md íŒŒì„œë¥¼ í†µí•´ ì½”ë“œâ†’ì˜ë¬¸ ë¼ë²¨ ë§¤í•‘ì„ ìƒì„±
    md_candidates = md_candidates or [
        'encoded_label.md', './encoded_label.md',
        'insight/encoded_label.md', './insight/encoded_label.md',
        '../insight/encoded_label.md'
    ]
    maps = {}
    def parse(path: Path):
        nonlocal maps
        try:
            with path.open('r', encoding='utf-8') as f:
                current = None
                for line in f:
                    s = line.strip()
                    if s.startswith('[') and s.endswith(']') and len(s) > 2:
                        current = s[1:-1]
                        maps[current] = {}
                    elif '->' in s and current:
                        parts = s.split('->', 1)
                        k = parts[0].strip().lstrip('-').strip()
                        v = parts[1].strip()
                        if k.isdigit():
                            try:
                                maps[current][int(k)] = v
                            except Exception:
                                pass
        except Exception:
            return False
        return True
    for p in md_candidates:
        path = Path(p)
        if path.exists() and parse(path):
            break
    return maps

# SEER ICD-O-3 Primary Site(ì •ìˆ˜ ì½”ë“œ) â†’ í•œêµ­ì–´ ì„¸ë¶€ ë¶€ìœ„ëª… ë§¤í•‘
def map_primary_site_code_to_korean(code) -> str:
    try:
        c = int(code)
    except Exception:
        # ìˆ«ì ì•„ë‹˜: ê·¸ëŒ€ë¡œ ë°˜í™˜
        return str(code)

    # 3ìë¦¬(ì˜ˆ: 341 â†’ C34.1) ë‹¨ìœ„ì˜ ì„¸ë¶€ ë§¤í•‘ ìš°ì„ 
    specific = {
        # ì‹ë„(C15.x)
        150: 'ì‹ë„-ê²½ë¶€', 151: 'ì‹ë„-í‰ë¶€', 152: 'ì‹ë„-ë³µë¶€', 153: 'ì‹ë„-ìƒë¶€ 1/3', 154: 'ì‹ë„-ì¤‘ë¶€ 1/3', 155: 'ì‹ë„-í•˜ë¶€ 1/3',
        158: 'ì‹ë„-ì¤‘ì²©ë³‘ë³€', 159: 'ì‹ë„, ê¸°íƒ€ë¶ˆëª…',
        # ìœ„(C16.x)
        160: 'ìœ„-ë¶„ë¬¸', 161: 'ìœ„-ì €ë¶€', 162: 'ìœ„-ì²´ë¶€', 163: 'ìœ„-ìœ ë¬¸ì „ì •ë¶€', 164: 'ìœ„-ìœ ë¬¸', 165: 'ìœ„-ì†Œë§Œ', 166: 'ìœ„-ëŒ€ë§Œ',
        168: 'ìœ„-ì¤‘ì²©ë³‘ë³€', 169: 'ìœ„, ê¸°íƒ€ë¶ˆëª…',
        # ì†Œì¥(C17.x)
        170: 'ì†Œì¥', 171: 'ì‹­ì´ì§€ì¥', 172: 'ê³µì¥', 173: 'íšŒì¥', 178: 'ì†Œì¥-ì¤‘ì²©ë³‘ë³€', 179: 'ì†Œì¥, ê¸°íƒ€ë¶ˆëª…',
        # ëŒ€ì¥(C18.x)
        180: 'ë§¹ì¥', 181: 'ì¶©ìˆ˜', 182: 'ìƒí–‰ê²°ì¥', 183: 'ê°„ë§Œê³¡', 184: 'íš¡í–‰ê²°ì¥', 185: 'ë¹„ë§Œê³¡', 186: 'í•˜í–‰ê²°ì¥',
        187: 'ì—ìŠ¤ìƒê²°ì¥', 188: 'ëŒ€ì¥-ì¤‘ì²©ë³‘ë³€', 189: 'ëŒ€ì¥, ê¸°íƒ€ë¶ˆëª…',
        # ì§ì¥êµ¬ë¶ˆ/ì§ì¥(C19â€“20)
        190: 'ì§ì¥êµ¬ë¶ˆê²°ì¥ ì´í–‰ë¶€', 200: 'ì§ì¥',
        # í•­ë¬¸(C21.x)
        210: 'í•­ë¬¸', 211: 'í•­ë¬¸ê´€', 212: 'ë°°ì„¤ê°•', 218: 'ì§ì¥/í•­ë¬¸-ì¤‘ì²©ë³‘ë³€', 219: 'ì§ì¥/í•­ë¬¸, ê¸°íƒ€ë¶ˆëª…',
        # ê°„/ë‹´ë„(C22â€“C24)
        220: 'ê°„', 221: 'ê°„ë‚´ ë‹´ê´€', 230: 'ë‹´ë‚­', 240: 'ê°„ì™¸ ë‹´ê´€', 241: 'ë°”í„° íŒ½ëŒ€ë¶€', 248: 'ë‹´ë„-ì¤‘ì²©ë³‘ë³€', 249: 'ë‹´ë„, ê¸°íƒ€ë¶ˆëª…',
        # ì·Œì¥(C25.x)
        250: 'ì·Œì¥ë‘ë¶€', 251: 'ì·Œì¥ì²´ë¶€', 252: 'ì·Œì¥ë¯¸ë¶€', 253: 'ì·Œì¥ê´€', 254: 'ë‘ê²Œë¥´í•œìŠ¤ì„¬', 258: 'ì·Œì¥-ì¤‘ì²©ë³‘ë³€', 259: 'ì·Œì¥, ê¸°íƒ€ë¶ˆëª…',
        # í˜¸í¡ê¸°(C30â€“C35)
        300: 'ì½”/ë¹„ê°•/ì¤‘ì´', 310: 'ë¶€ë¹„ë™', 320: 'í›„ë‘', 330: 'ê¸°ê´€',
        340: 'ì£¼ê¸°ê´€ì§€', 341: 'í-ìƒì—½', 342: 'í-ì¤‘ì—½', 343: 'í-í•˜ì—½', 348: 'í-ì¤‘ì²©ë³‘ë³€', 349: 'í, ê¸°íƒ€ë¶ˆëª…',
        350: 'ê¸°íƒ€ í˜¸í¡ê¸°ê´€',
        # ë¼ˆ/í”¼ë¶€/ì—°ì¡°ì§(C40â€“C49)
        400: 'ë¼ˆ ë° ê´€ì ˆ', 401: 'ë¼ˆ ë° ê´€ì ˆ', 430: 'í”¼ë¶€ í‘ìƒ‰ì¢…', 440: 'ë¹„í‘ìƒ‰ì¢… í”¼ë¶€ì•”', 490: 'ì—°ì¡°ì§(ì‹¬ì¥ í¬í•¨)',
        # ë³µë§‰/í›„ë³µë§‰(C48)
        480: 'í›„ë³µë§‰', 481: 'ë³µë§‰', 488: 'ë³µë§‰/í›„ë³µë§‰-ì¤‘ì²©ë³‘ë³€', 489: 'ë³µë§‰/í›„ë³µë§‰, ê¸°íƒ€ë¶ˆëª…',
        # ìœ ë°©/ìƒì‹ê¸°(C50â€“C63)
        500: 'ìœ ë°©', 510: 'ì™¸ìŒë¶€', 520: 'ì§ˆ', 530: 'ìê¶ê²½ë¶€', 540: 'ìê¶ì²´ë¶€', 550: 'ìê¶, ê¸°íƒ€ë¶ˆëª…', 560: 'ë‚œì†Œ', 570: 'ê¸°íƒ€ ì—¬ì„± ìƒì‹ê¸°ê´€',
        600: 'ìŒê²½', 610: 'ì „ë¦½ì„ ', 620: 'ê³ í™˜', 630: 'ê¸°íƒ€ ë‚¨ì„± ìƒì‹ê¸°ê´€',
        # ìš”ë¡œ(C64â€“C68)
        640: 'ì‹ ì¥', 650: 'ì‹ ìš°', 660: 'ìš”ê´€', 670: 'ë°©ê´‘', 680: 'ê¸°íƒ€ ìš”ë¡œê¸°ê´€',
        # ëˆˆ/ë‡Œ/ì‹ ê²½ê³„(C69â€“C72)
        690: 'ëˆˆ ë° ì•ˆì™€', 700: 'ìˆ˜ë§‰', 710: 'ë‡Œ', 720: 'ë‡Œì‹ ê²½ ë° ê¸°íƒ€ ì‹ ê²½ê³„',
        # ë‚´ë¶„ë¹„(C73â€“C75)
        730: 'ê°‘ìƒì„ ', 739: 'ê°‘ìƒì„ ', 740: 'ë¶€ê°‘ìƒì„ ', 741: 'ë¶€ì‹ ', 750: 'ê¸°íƒ€ ë‚´ë¶„ë¹„'
    }
    if c in specific:
        return specific[c]

    # ëŒ€ë¶„ë¥˜(ì• ë‘ ìë¦¬) ê¸°ë³¸ ë§¤í•‘ìœ¼ë¡œ í´ë°±
    major = c // 10
    major_map = {
        15: 'ì‹ë„', 16: 'ìœ„', 17: 'ì†Œì¥', 18: 'ëŒ€ì¥', 19: 'ì§ì¥êµ¬ë¶ˆê²°ì¥ ì´í–‰ë¶€', 20: 'ì§ì¥', 21: 'í•­ë¬¸ ë° í•­ë¬¸ê´€',
        22: 'ê°„ ë° ê°„ë‚´ ë‹´ê´€', 23: 'ë‹´ë‚­', 24: 'ê¸°íƒ€ ë‹´ë„', 25: 'ì·Œì¥', 26: 'ê¸°íƒ€ ì†Œí™”ê¸°ê´€',
        30: 'ì½”/ë¹„ê°•/ì¤‘ì´', 31: 'ë¶€ë¹„ë™', 32: 'í›„ë‘', 33: 'ê¸°ê´€', 34: 'í ë° ê¸°ê´€ì§€', 35: 'ê¸°íƒ€ í˜¸í¡/í‰ê°• ì¥ê¸°',
        40: 'ë¼ˆ ë° ê´€ì ˆ', 41: 'ë¼ˆ ë° ê´€ì ˆ', 43: 'í”¼ë¶€ í‘ìƒ‰ì¢…', 44: 'ë¹„í‘ìƒ‰ì¢… í”¼ë¶€ì•”', 49: 'ì—°ì¡°ì§(ì‹¬ì¥ í¬í•¨)',
        48: 'í›„ë³µë§‰/ë³µë§‰',
        50: 'ìœ ë°©', 51: 'ì™¸ìŒë¶€', 52: 'ì§ˆ', 53: 'ìê¶ê²½ë¶€', 54: 'ìê¶ì²´ë¶€', 55: 'ìê¶, ê¸°íƒ€ë¶ˆëª…', 56: 'ë‚œì†Œ', 57: 'ê¸°íƒ€ ì—¬ì„± ìƒì‹ê¸°ê´€',
        60: 'ìŒê²½', 61: 'ì „ë¦½ì„ ', 62: 'ê³ í™˜', 63: 'ê¸°íƒ€ ë‚¨ì„± ìƒì‹ê¸°ê´€',
        64: 'ì‹ ì¥', 65: 'ì‹ ìš°', 66: 'ìš”ê´€', 67: 'ë°©ê´‘', 68: 'ê¸°íƒ€ ìš”ë¡œê¸°ê´€',
        69: 'ëˆˆ ë° ì•ˆì™€', 70: 'ìˆ˜ë§‰', 71: 'ë‡Œ', 72: 'ë‡Œì‹ ê²½ ë° ê¸°íƒ€ ì‹ ê²½ê³„',
        73: 'ê°‘ìƒì„ ', 74: 'ë¶€ì‹ ', 75: 'ê¸°íƒ€ ë‚´ë¶„ë¹„(í‰ì„  í¬í•¨)',
        76: 'íŠ¹ì •ë¶€ìœ„ë¶ˆëª…/ë¯¸ìƒ', 77: 'ë¦¼í”„ì ˆ', 78: 'ì „ì´ì„±ì•”(í˜¸í¡/ì†Œí™”ê¸°)', 79: 'ì „ì´ì„±ì•”(ê¸°íƒ€)', 80: 'ì›ë°œë¶€ìœ„ ë¶ˆëª…'
    }
    return major_map.get(major, str(code))

def _augment_decoded_labels(encoded_cod_df):
    # ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ __label ë° __label_kor ì»¬ëŸ¼ì„ ë³´ê°•
    maps = _load_decoding_maps_from_md()
    dec_targets = {
        'COD to site recode__enc': ('COD to site recode', maps.get('COD to site recode', {})),
        'Vital status recode (study cutoff used)__enc': ('Vital status recode (study cutoff used)', maps.get('Vital status recode (study cutoff used)', {})),
        'Survival months flag__enc': ('Survival months flag', maps.get('Survival months flag', {})),
    }
    df = encoded_cod_df
    # ê¸°ë³¸ ì˜/í•œ ë§¤í•‘ (í•„ìˆ˜ í•­ëª© ìš°ì„ )
    vital_en_map = {0: 'Alive', 1: 'Dead'}
    vital_kor_from_en = {'Alive': 'ìƒì¡´', 'Dead': 'ì‚¬ë§'}
    survflag_kor_from_en = {
        'Complete dates are available and there are more than 0 days of survival': 'ì™„ì „í•œ ë‚ ì§œ, ìƒì¡´ì¼ìˆ˜ > 0',
        'Incomplete dates are available and there cannot be zero days of follow-up': 'ë¶ˆì™„ì „ ë‚ ì§œ, ì¶”ì  0ì¼ ë¶ˆê°€',
        'Not calculated because a Death Certificate Only or Autopsy Only case': 'ì‚¬ë§ì§„ë‹¨ì„œ/ë¶€ê²€ë§Œ, ë¯¸ê³„ì‚°',
        'Complete dates are available and there are 0 days of survival': 'ì™„ì „í•œ ë‚ ì§œ, ìƒì¡´ì¼ìˆ˜ 0',
        'Incomplete dates are available and there could be zero days of follow-up': 'ë¶ˆì™„ì „ ë‚ ì§œ, ì¶”ì  0ì¼ ê°€ëŠ¥',
    }
    # COD í•œê¸€ ë§¤í•‘(ì½”ë“œ ê¸°ë°˜; ì˜ë¬¸ ë§¤í•‘ ë¶€ì¬ì‹œ ëŒ€ë¹„)
    cod_ko_by_code = {
        0: 'ìƒì¡´', 1: 'ê°„ë‚´ë‹´ê´€', 2: 'í ë° ê¸°ê´€ì§€', 3: 'ê¸°íƒ€ ì•…ì„±ì¢…ì–‘', 4: 'ê¸°íƒ€ ì‚¬ë§ì›ì¸', 5: 'ëŒ€ì¥(ì§ì¥ ì œì™¸)',
        6: 'ì‹¬ì¥ì§ˆí™˜', 7: 'ì•Œì¸ í•˜ì´ë¨¸', 8: 'ìœ„', 9: 'ì‹ ì¥ì§ˆí™˜(ì‹ ì¦í›„êµ° í¬í•¨)', 10: 'ë‡Œí˜ˆê´€ì§ˆí™˜', 11: 'ê°„', 12: 'ìœ ë°©',
        13: 'ë§Œì„±íì‡„ì„±íì§ˆí™˜', 14: 'ë§Œì„± ë¦¼í”„êµ¬ì„± ë°±í˜ˆë³‘', 15: 'ë§Œì„± ê°„ì§ˆí™˜/ê°„ê²½í™”', 18: 'ì „ë¦½ì„ ', 19: 'ë¹„í˜¸ì§€í‚¨ ë¦¼í”„ì¢…',
        20: 'ë‹¹ë‡¨ë³‘', 21: 'ì‚¬ë§ì›ì¸ ë¯¸ìƒ', 22: 'ì‹ ì¥ ë° ì‹ ìš°', 23: 'ê³ í˜ˆì••(ì‹¬ì¥ì§ˆí™˜ ë™ë°˜ ì—†ìŒ)', 24: 'ë‹¤ë°œì„± ê³¨ìˆ˜ì¢…',
        25: 'ê¸‰ì„± ê³¨ìˆ˜ì„± ë°±í˜ˆë³‘', 26: 'ë‡Œ ë° ê¸°íƒ€ ì‹ ê²½ê³„', 27: 'íë ´/ì¸í”Œë£¨ì—”ì', 28: 'ì·Œì¥', 31: 'ì‚¬ê³  ë° ë¶€ì‘ìš©',
        32: 'ìê¶ì²´ë¶€', 33: 'ë°©ê´‘', 34: 'ì œìë¦¬/ì–‘ì„±/ë¯¸í™•ì • ì‹ ìƒë¬¼', 35: 'ì£½ìƒê²½í™”ì¦', 36: 'ì‹ë„', 37: 'ìê¶ê²½ë¶€',
        38: 'ìì‚´/ìí•´', 40: 'í”¼ë¶€ í‘ìƒ‰ì¢…', 41: 'ì§ì¥ ë° ì§ì¥ê²°ì¥ ì´í–‰ë¶€', 42: 'ìê¶, ê¸°íƒ€íŠ¹ì •ë¶ˆê°€', 43: 'ì—°ì¡°ì§(ì‹¬ì¥ í¬í•¨)',
        44: 'ë¹„í‘ìƒ‰ì¢… í”¼ë¶€ì•”', 45: 'í˜€', 46: 'íŒ¨í˜ˆì¦', 47: 'ê°‘ìƒì„ ', 52: 'í‰ë§‰', 53: 'ë‚œì†Œ', 54: 'ê¸°íƒ€ ë‹´ë„', 61: 'ë¼ˆ/ê´€ì ˆ',
        62: 'í¸ë„', 63: 'ë³µë§‰/ë§/ì¥ê°„ë§‰', 64: 'í›„ë‘', 65: 'í˜¸ì§€í‚¨ ë¦¼í”„ì¢…', 66: 'í›„ë³µë§‰', 68: 'ê²°í•µ', 70: 'êµ¬ì¸ë‘', 71: 'ì§ˆ',
        72: 'ë‹´ë‚­', 73: 'ì¹˜ì€/ê¸°íƒ€ êµ¬ê°•', 74: 'ê¸°íƒ€ ë‚´ë¶„ë¹„(í‰ì„  í¬í•¨)', 76: 'ê¸°ê´€/ì¢…ê²©/ê¸°íƒ€ í˜¸í¡ê¸°ê´€', 77: 'ê³ í™˜',
        78: 'ê¸‰ì„± ë¦¼í”„êµ¬ì„± ë°±í˜ˆë³‘', 79: 'ê¸°íƒ€ ìš”ë¡œê¸°ê´€', 80: 'ê¸°íƒ€ êµ¬ê°•/ì¸ë‘', 81: 'ê¸°íƒ€ ì—¬ì„± ìƒì‹ê¸°ê´€', 82: 'ì½”/ë¹„ê°•/ì¤‘ì´',
        83: 'ê¸°íƒ€ ê¸‰ì„± ë°±í˜ˆë³‘', 84: 'ìš”ê´€', 85: 'ì™¸ìŒë¶€', 86: 'ë§Œì„± ê³¨ìˆ˜ì„± ë°±í˜ˆë³‘', 87: 'ëˆˆ/ì•ˆì™€', 88: 'ì…ìˆ ', 89: 'ì„ì‹ /ì¶œì‚°/ì‚°ìš• í•©ë³‘ì¦'
    }
    cod_en_by_code = maps.get('COD to site recode', {})
    cod_en_to_ko = {en: cod_ko_by_code.get(code, en) for code, en in cod_en_by_code.items()}

    for enc_col, (orig_col, mapping) in dec_targets.items():
        if enc_col not in df.columns:
            continue
        # ì˜ë¬¸ ë¼ë²¨
        if mapping:
            df[orig_col] = df[enc_col].map(mapping)
            df[enc_col.replace('__enc', '__label')] = df[enc_col].map(mapping)
        elif enc_col.endswith('Vital status recode (study cutoff used)__enc'):
            df[enc_col.replace('__enc', '__label')] = df[enc_col].map(vital_en_map)
        elif enc_col.endswith('COD to site recode__enc'):
            df[enc_col.replace('__enc', '__label_kor')] = df[enc_col].map(cod_ko_by_code)
        # í•œê¸€ ë¼ë²¨ ì¶”ê°€
        lab = enc_col.replace('__enc', '__label')
        lab_k = enc_col.replace('__enc', '__label_kor')
        if lab in df.columns:
            if orig_col == 'COD to site recode':
                df[lab_k] = df[lab].map(cod_en_to_ko)
            elif orig_col == 'Vital status recode (study cutoff used)':
                df[lab_k] = df[lab].map(vital_kor_from_en)
            elif orig_col == 'Survival months flag':
                df[lab_k] = df[lab].map(survflag_kor_from_en)
    # Primary Site í•œêµ­ì–´ ìƒì„¸ ë¼ë²¨ ë³´ê°•
    try:
        if 'Primary Site' in df.columns and 'Primary Site__label_kor' not in df.columns:
            df['Primary Site__label_kor'] = df['Primary Site'].map(map_primary_site_code_to_korean)
    except Exception:
        ...
    return df

def _ensure_survival_bin(df, col='Survival months', out_col='Survival months_bin_3m'):
    # ìƒì¡´ ê°œì›” ìˆ˜ë¥¼ 3ê°œì›” ë‹¨ìœ„ êµ¬ê°„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” íŒŒìƒì—´ ìƒì„±(ì—†ì„ ë•Œë§Œ ìƒì„±)
    if out_col in df.columns:
        return df
    if col in df.columns:
        df = df.copy()
        df[out_col] = DataModify.DataPreprocessing.bin_survival_months(df[col], bin_size=3)
    return df


def _plot_corr_with_target(encoded_df):
    # [íˆíŠ¸ë§µ] ì¸ì½”ë”©ëœ ìˆ˜ì¹˜ í”¼ì²˜ vs target_labelì˜ ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ ì‹œê°í™”(ì „ì²´/ìƒìœ„ TOP-N)
    if 'target_label' not in encoded_df.columns:
        return
    num_cols = [c for c in encoded_df.columns if pd.api.types.is_numeric_dtype(encoded_df[c])]
    # ë¶ˆí•„ìš” ì‹ë³„ì ì»¬ëŸ¼ ì œì™¸
    exclude_cols = {'Unnamed: 0', 'Patient ID'}
    num_cols = [c for c in num_cols if c not in exclude_cols]
    if not num_cols:
        return
    corr_with_target = encoded_df[num_cols].corrwith(encoded_df['target_label'], method='spearman').dropna()
    if corr_with_target.empty:
        return
    # í•œêµ­ì–´ ë¼ë²¨ ë§¤í•‘
    kor_map = {
        'Sex': 'ì„±ë³„',
        'Age recode with <1 year olds and 90+': 'ì—°ë ¹ëŒ€',
        'Year of diagnosis': 'ì§„ë‹¨ ì—°ë„',
        'Year of follow-up recode': 'ì¶”ì  ì—°ë„',
        'Race recode (W, B, AI, API)': 'ì¸ì¢… ì¬ì½”ë“œ',
        'Site recode ICD-O-3/WHO 2008': 'ì•” ë¶€ìœ„ ì¬ì½”ë“œ',
        'Primary Site': 'ì›ë°œ ë¶€ìœ„',
        'Primary Site - labeled': 'ì›ë°œ ë¶€ìœ„ ë¼ë²¨',
        'Derived Summary Grade 2018 (2018+)': 'ìš”ì•½ ë“±ê¸‰ 2018',
        'Laterality': 'ì¢Œìš° êµ¬ë¶„',
        'EOD Schema ID Recode (2010+)': 'EOD ìŠ¤í‚¤ë§ˆ ì¬ì½”ë“œ',
        'Combined Summary Stage with Expanded Regional Codes (2004+)': 'SEER ìš”ì•½ ë³‘ê¸°(í™•ì¥)',
        'RX Summ--Surg Prim Site (1998+)': 'ìˆ˜ìˆ  ì½”ë“œ',
        'RX Summ--Scope Reg LN Sur (2003+)': 'ë¦¼í”„ì ˆ ì ˆì œ ë²”ìœ„',
        'RX Summ--Surg Oth Reg/Dis (2003+)': 'ê¸°íƒ€ ìˆ˜ìˆ ',
        'Sequence number': 'ìˆœì„œ ë²ˆí˜¸',
        'Median household income inflation adj to 2023': 'ê°€êµ¬ ì†Œë“(2023 ë¬¼ê°€ë³´ì •)',
        'Number of Cores Positive Recode (2010+)': 'ì–‘ì„± ì½”ì–´ ìˆ˜',
        'Number of Cores Examined Recode (2010+)': 'ê²€ì‚¬ ì½”ì–´ ìˆ˜',
        'EOD Primary Tumor Recode (2018+)': 'EOD ì›ë°œ ì¢…ì–‘',
        'PRCDA 2020': 'PRCDA 2020',
        'Survival months': 'ìƒì¡´ ê°œì›”',
        'Survival months_bin_3m': 'ìƒì¡´ ê°œì›”(3ê°œì›” êµ¬ê°„)',
        'target_label': 'íƒ€ê¹ƒ ë¼ë²¨',
        'Vital status recode (study cutoff used)__enc': 'ìƒì¡´ ìƒíƒœ(ì¸ì½”ë”©)'
    }
    heat = corr_with_target.sort_values(ascending=False).to_frame(name='Spearman r')
    # ì¸ë±ìŠ¤(í”¼ì²˜ëª…)ë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜
    heat.index = [kor_map.get(str(idx), str(idx)) for idx in heat.index]
    plt.figure(figsize=(8, max(3, 0.25 * len(heat))))
    sns.heatmap(heat, annot=True, fmt='.3f', cmap='vlag', vmin=-1, vmax=1, cbar=True)
    plt.title('Spearman correlation with target_label (encoded features)')
    plt.xlabel('')
    plt.ylabel('ë³€ìˆ˜')
    plt.tight_layout()
    plt.show()

    top_n = min(25, len(heat))
    top_abs = corr_with_target.reindex(corr_with_target.abs().sort_values(ascending=False).head(top_n).index)
    heat2 = top_abs.to_frame(name='Spearman r')
    heat2.index = [kor_map.get(str(idx), str(idx)) for idx in heat2.index]
    plt.figure(figsize=(8, max(3, 0.35 * len(heat2))))
    sns.heatmap(heat2, annot=True, fmt='.3f', cmap='vlag', vmin=-1, vmax=1, cbar=True)
    plt.title(f'Top-{top_n} |Spearman r| with target_label')
    plt.xlabel('')
    plt.ylabel('ë³€ìˆ˜')
    plt.tight_layout()
    plt.show()


def _plot_survival_months(encoded_df):
    # [ì‹œê³„ì—´] ìƒì¡´ê°œì›”ì— ë”°ë¥¸ ì‚¬ê±´í™•ë¥ (= target_label != -1) ë³€í™”
    # - ì›” ë‹¨ìœ„ ê³¡ì„  + 3ê°œì›” êµ¬ê°„ ê³¡ì„ (ë…¸ì´ì¦ˆ ì™„í™”ë¥¼ ìœ„í•œ ìŠ¤ë¬´ë”© í¬í•¨)
    cols = ['Survival months', 'Survival months_bin_3m', 'target_label']
    df = _ensure_survival_bin(encoded_df, 'Survival months', 'Survival months_bin_3m')
    if not all(c in df.columns for c in cols):
        return
    tmp = df[cols].dropna(subset=['Survival months']).copy()
    tmp['is_death'] = (tmp['target_label'] != -1).astype(int)
    grp_m = tmp.groupby('Survival months').agg(p_death=('is_death','mean'), n=('is_death','size')).reset_index().sort_values('Survival months')
    n_min = 50
    grp_mf = grp_m[grp_m['n'] >= n_min].copy()
    grp_mf['p_smooth'] = grp_mf['p_death'].rolling(window=3, center=True, min_periods=1).mean()
    plt.figure(figsize=(6, 4))
    plt.plot(grp_mf['Survival months'], grp_mf['p_death'], color='tab:blue', alpha=0.35, label='Monthly p(death)')
    plt.plot(grp_mf['Survival months'], grp_mf['p_smooth'], color='tab:blue', linewidth=2.0, label='Monthly (smoothed)')
    plt.ylim(0, 1)
    plt.title('Death probability over Survival months')
    plt.xlabel('Survival months')
    plt.ylabel('P(target_label != -1)')
    plt.legend()
    plt.tight_layout()
    plt.show()

    grp_b = tmp.groupby('Survival months_bin_3m').agg(p_death=('is_death','mean'), n=('is_death','size')).reset_index().sort_values('Survival months_bin_3m')
    grp_bf = grp_b[grp_b['n'] >= n_min].copy()
    grp_bf['p_smooth'] = grp_bf['p_death'].rolling(window=3, center=True, min_periods=1).mean()
    plt.figure(figsize=(6, 4))
    plt.plot(grp_bf['Survival months_bin_3m'], grp_bf['p_death'], color='tab:orange', alpha=0.35, label='3-month bin p(death)')
    plt.plot(grp_bf['Survival months_bin_3m'], grp_bf['p_smooth'], color='tab:orange', linewidth=2.0, label='3-month (smoothed)')
    plt.ylim(0, 1)
    plt.title('Death probability over 3-month bins')
    plt.xlabel('Survival months (3-month bins)')
    plt.ylabel('P(target_label != -1)')
    plt.legend()
    plt.tight_layout()
    plt.show()


def _plot_basic_distributions(encoded_cod_df):
    # [ê¸°ë³¸ ë¶„í¬] ì„±ë³„(íŒŒì´), ì—°ë ¹ëŒ€(ë§‰ëŒ€), ìƒì¡´ ìƒíƒœ(íŒŒì´), ì§„ë‹¨ì—°ë„(ë¼ì¸)
    df = _augment_decoded_labels(encoded_cod_df.copy())
    cols = ['Sex', 'Age recode with <1 year olds and 90+', 'Year of diagnosis']
    if not any(c in df.columns for c in cols):
        return
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

    # ì„±ë³„ ë¶„í¬ (íŒŒì´)
    if 'Sex' in df.columns:
        sex_counts = df['Sex'].value_counts()
        sex_labels = ['ì—¬ì„±', 'ë‚¨ì„±'] if len(sex_counts) == 2 else [f'Sex_{i}' for i in sex_counts.index]
        colors = ['#FF6B9D', '#4DABF7']
        ax1.pie(sex_counts.values, labels=sex_labels, autopct='%1.1f%%', colors=colors, startangle=90)
        ax1.set_title('ì„±ë³„ ë¶„í¬', fontsize=14, fontweight='bold', pad=20)
    else:
        ax1.axis('off')

    # ì—°ë ¹ëŒ€ë³„ í™˜ì ë¶„í¬ (ë§‰ëŒ€)
    age_order = DataModify.DataPreprocessing.AGE_RECODE_ORDER
    age_kor_map = {'00 years':'0','01-04 years':'1-4','05-09 years':'5-9','10-14 years':'10-14','15-19 years':'15-19','20-24 years':'20-24','25-29 years':'25-29','30-34 years':'30-34','35-39 years':'35-39','40-44 years':'40-44','45-49 years':'45-49','50-54 years':'50-54','55-59 years':'55-59','60-64 years':'60-64','65-69 years':'65-69','70-74 years':'70-74','75-79 years':'75-79','80-84 years':'80-84','85-89 years':'85-89','90+ years':'90 ì´ìƒ'}
    age_col = 'Age recode with <1 year olds and 90+'
    if age_col in df.columns:
        _series = df[age_col]
        _num = pd.to_numeric(_series, errors='coerce')
        if _num.notna().sum() > 0:
            _codes = _num.dropna().astype(int)
            age_counts_raw = _codes.value_counts().sort_index()
            order_codes = [i for i in range(len(age_order)) if i in age_counts_raw.index]
            age_counts = age_counts_raw.reindex(order_codes).fillna(0).astype(int)
            xticklabels = [age_kor_map[age_order[i]] for i in age_counts.index]
        else:
            age_counts_raw = _series.value_counts()
            ages_present = [a for a in age_order if a in age_counts_raw.index]
            age_counts = age_counts_raw.reindex(ages_present).fillna(0).astype(int)
            xticklabels = [age_kor_map.get(a, a) for a in age_counts.index]
        positions = np.arange(len(age_counts))
        ax2.bar(positions, age_counts.values, color='#51CF66', alpha=0.8)
        ax2.set_title('ì—°ë ¹ëŒ€ë³„ í™˜ì ë¶„í¬', fontsize=14, fontweight='bold', pad=20)
        ax2.set_xlabel('ì—°ë ¹ëŒ€'); ax2.set_ylabel('í™˜ì ìˆ˜')
        ax2.set_xticks(positions); ax2.set_xticklabels(xticklabels, rotation=45, ha='center')
        ax2.set_axisbelow(True); ax2.grid(axis='y', linestyle='--', alpha=0.3)
        top_ages = age_counts.nlargest(5)
        for i_pos, (age_key, count) in enumerate(zip(age_counts.index, age_counts.values)):
            if age_key in top_ages.index:
                ax2.text(positions[i_pos], count + max(1, age_counts.max()*0.01), f'{count:,}', ha='center', va='bottom', fontsize=9, fontweight='bold')
    else:
        ax2.axis('off')

    # ìƒì¡´ ìƒíƒœ ë¶„í¬ (íŒŒì´, í•œê¸€ ë¼ë²¨)
    vital_kor_col = 'Vital status recode (study cutoff used)__label_kor'
    if vital_kor_col in df.columns:
        vital_status = df[vital_kor_col].value_counts()
        colors_vital = ['#69DB7C', '#FF8787']
        ax3.pie(vital_status.values, labels=vital_status.index.tolist(), autopct='%1.1f%%', colors=colors_vital, startangle=90, wedgeprops=dict(width=0.6))
        ax3.set_title('ìƒì¡´ ìƒíƒœ ë¶„í¬', fontsize=14, fontweight='bold', pad=20)
    else:
        ax3.axis('off')

    # ì§„ë‹¨ ì—°ë„ë³„ í™˜ì ìˆ˜ ì¶”ì´ (ë¼ì¸)
    if 'Year of diagnosis' in df.columns:
        yr = df['Year of diagnosis'].value_counts().sort_index()
        ax4.plot(yr.index.astype(int), yr.values, marker='o', linewidth=2)
        ax4.set_title('ì§„ë‹¨ ì—°ë„ë³„ í™˜ì ìˆ˜ ì¶”ì´', fontsize=14, fontweight='bold', pad=20)
        ax4.set_xlabel('ì§„ë‹¨ ì—°ë„'); ax4.set_ylabel('í™˜ì ìˆ˜'); ax4.grid(True, alpha=0.3)
    else:
        ax4.axis('off')
    plt.tight_layout(); plt.show()


def _plot_site_survival_year(encoded_cod_df):
    # [ì•” ë¶€ìœ„/ì—°ë ¹/ì—°ë„] ë…¸íŠ¸ë¶ ë¡œì§ì— ë§ì¶˜ 4ê°œ ì„œë¸Œí”Œë¡¯
    df = _augment_decoded_labels(encoded_cod_df.copy())
    # (ë¶€ìœ„) í•œê¸€ ë§¤í•‘ ë° í—¬í¼
    site_korean_mapping = {
        'Lung and Bronchus': 'í ë° ê¸°ê´€ì§€','Breast': 'ìœ ë°©','Prostate': 'ì „ë¦½ì„ ','Stomach': 'ìœ„','Liver': 'ê°„','Pancreas': 'ì·Œì¥','Esophagus': 'ì‹ë„','Ovary': 'ë‚œì†Œ',
        'Kidney and Renal Pelvis': 'ì‹ ì¥ ë° ì‹ ìš°','Urinary Bladder': 'ë°©ê´‘','Rectum': 'ì§ì¥','Rectosigmoid Junction': 'ì§ì¥êµ¬ë¶ˆê²°ì¥ ì´í–‰ë¶€',
        'Ascending Colon': 'ìƒí–‰ê²°ì¥','Sigmoid Colon': 'ì—ìŠ¤ìƒê²°ì¥','Transverse Colon': 'íš¡í–‰ê²°ì¥','Descending Colon': 'í•˜í–‰ê²°ì¥',
        'Cecum': 'ë§¹ì¥','Large Intestine, NOS': 'ëŒ€ì¥, ê¸°íƒ€ë¶ˆëª…','Thyroid': 'ê°‘ìƒì„ ','Brain': 'ë‡Œ','Melanoma of the Skin': 'í”¼ë¶€ í‘ìƒ‰ì¢…',
        'NHL - Nodal': 'ë¹„í˜¸ì§€í‚¨ë¦¼í”„ì¢… - ë¦¼í”„ì ˆ','NHL - Extranodal': 'ë¹„í˜¸ì§€í‚¨ë¦¼í”„ì¢… - ë¦¼í”„ì ˆì™¸','Hodgkin - Nodal': 'í˜¸ì§€í‚¨ë¦¼í”„ì¢… - ë¦¼í”„ì ˆ','Hodgkin - Extranodal': 'í˜¸ì§€í‚¨ë¦¼í”„ì¢… - ë¦¼í”„ì ˆì™¸',
        'Cranial Nerves Other Nervous System': 'ë‡Œì‹ ê²½ ë° ê¸°íƒ€ ì‹ ê²½ê³„','Gum and Other Mouth': 'ì¹˜ì€ ë° ê¸°íƒ€ êµ¬ê°•','Tongue': 'í˜€','Tonsil': 'í¸ë„',
        'Larynx': 'í›„ë‘','Nasopharynx': 'ë¹„ì¸ë‘','Oropharynx': 'êµ¬ì¸ë‘','Hypopharynx': 'í•˜ì¸ë‘','Nose, Nasal Cavity and Middle Ear': 'ì½”/ë¹„ê°•/ì¤‘ì´',
        'Eye and Orbit': 'ëˆˆ ë° ì•ˆì™€','Soft Tissue including Heart': 'ì—°ì¡°ì§(ì‹¬ì¥ í¬í•¨)','Bones and Joints': 'ë¼ˆ ë° ê´€ì ˆ','Salivary Gland': 'íƒ€ì•¡ì„ ',
        'Uterus, NOS': 'ìê¶, ê¸°íƒ€ë¶ˆëª…','Cervix Uteri': 'ìê¶ê²½ë¶€','Corpus Uteri': 'ìê¶ì²´ë¶€','Vagina': 'ì§ˆ','Vulva': 'ì™¸ìŒë¶€','Penis': 'ìŒê²½','Testis': 'ê³ í™˜',
        'Gallbladder': 'ë‹´ë‚­','Intrahepatic Bile Duct': 'ê°„ë‚´ ë‹´ê´€','Other Biliary': 'ê¸°íƒ€ ë‹´ë„','Small Intestine': 'ì†Œì¥','Appendix': 'ì¶©ìˆ˜',
        'Peritoneum, Omentum and Mesentery': 'ë³µë§‰/ë§/ì¥ê°„ë§‰','Retroperitoneum': 'í›„ë³µë§‰',
        'Trachea, Mediastinum and Other Respiratory Organs': 'ê¸°ê´€/ì¢…ê²©ë™/ê¸°íƒ€ í˜¸í¡ê¸°ê´€',
    }
    def get_site_korean_name(name: str):
        try:
            key = str(name).strip()
            if key in site_korean_mapping:
                return site_korean_mapping[key]
            low = {k.lower(): v for k, v in site_korean_mapping.items()}
            return low.get(key.lower(), name)
        except Exception:
            return name

    df_site = df.copy()
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))

    # 3-1. ì£¼ìš” ì•” ë¶€ìœ„ ì½”ë“œë³„ í™˜ì ìˆ˜ (ìƒìœ„ 10ê°œ)
    if 'Primary Site' in df_site.columns:
        site_counts = df_site['Primary Site'].value_counts().head(10)
        colors_sites = plt.cm.viridis(np.linspace(0, 1, len(site_counts)))
        ax1.barh(range(len(site_counts)), site_counts.values, color=colors_sites)
        ax1.set_yticks(range(len(site_counts)))
        # Primary Site ì½”ë“œ(ì˜ˆ: 341, 163 ë“±)ë¥¼ í•œê¸€ ëª…ì¹­ìœ¼ë¡œ ë³€í™˜
        # - ìš°ì„  í…ìŠ¤íŠ¸ ë¼ë²¨ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©í•˜ê³ ,
        # - ì—†ì„ ê²½ìš° ICD-O-3 Topographyì˜ ì• 2ìë¦¬(Cxx)ë¡œ ëŒ€ë¶„ë¥˜ ë§µí•‘
        major_site_kor_map = {
            0: 'ì…ìˆ ',
            1: 'í˜€', 2: 'í˜€', 3: 'ì¹˜ì€', 4: 'êµ¬ê°•ì €', 5: 'êµ¬ê°œ', 6: 'ê¸°íƒ€ êµ¬ê°•',
            7: 'íƒ€ì•¡ì„ ', 8: 'íƒ€ì•¡ì„ ', 9: 'í¸ë„', 10: 'êµ¬ì¸ë‘', 11: 'ë¹„ì¸ë‘', 12: 'í•˜ì¸ë‘', 13: 'í•˜ì¸ë‘', 14: 'ê¸°íƒ€ êµ¬ê°•/ì¸ë‘',
            15: 'ì‹ë„', 16: 'ìœ„', 17: 'ì†Œì¥', 18: 'ëŒ€ì¥', 19: 'ì§ì¥êµ¬ë¶ˆê²°ì¥ ì´í–‰ë¶€', 20: 'ì§ì¥', 21: 'í•­ë¬¸ ë° í•­ë¬¸ê´€',
            22: 'ê°„ ë° ê°„ë‚´ ë‹´ê´€', 23: 'ë‹´ë‚­', 24: 'ê¸°íƒ€ ë‹´ë„', 25: 'ì·Œì¥', 26: 'ê¸°íƒ€ ì†Œí™”ê¸°ê´€',
            30: 'ì½”/ë¹„ê°•/ì¤‘ì´', 31: 'ë¶€ë¹„ë™', 32: 'í›„ë‘', 33: 'ê¸°ê´€', 34: 'í ë° ê¸°ê´€ì§€',
            37: 'í‰ì„ ', 38: 'ì‹¬ì¥/ì¢…ê²©ë™/í‰ë§‰', 39: 'ê¸°íƒ€ í˜¸í¡/í‰ê°• ì¥ê¸°',
            40: 'ë¼ˆ ë° ê´€ì ˆ', 41: 'ë¼ˆ ë° ê´€ì ˆ', 43: 'í”¼ë¶€ í‘ìƒ‰ì¢…', 44: 'ë¹„í‘ìƒ‰ì¢… í”¼ë¶€ì•”',
            47: 'ë§ì´ˆì‹ ê²½ê³„', 48: 'í›„ë³µë§‰/ë³µë§‰', 49: 'ì—°ì¡°ì§(ì‹¬ì¥ í¬í•¨)',
            50: 'ìœ ë°©', 51: 'ì™¸ìŒë¶€', 52: 'ì§ˆ', 53: 'ìê¶ê²½ë¶€', 54: 'ìê¶ì²´ë¶€', 55: 'ìê¶, ê¸°íƒ€ë¶ˆëª…', 56: 'ë‚œì†Œ', 57: 'ê¸°íƒ€ ì—¬ì„± ìƒì‹ê¸°ê´€', 58: 'íƒœë°˜',
            60: 'ìŒê²½', 61: 'ì „ë¦½ì„ ', 62: 'ê³ í™˜', 63: 'ê¸°íƒ€ ë‚¨ì„± ìƒì‹ê¸°ê´€',
            64: 'ì‹ ì¥', 65: 'ì‹ ìš°', 66: 'ìš”ê´€', 67: 'ë°©ê´‘', 68: 'ê¸°íƒ€ ìš”ë¡œê¸°ê´€',
            69: 'ëˆˆ ë° ì•ˆì™€', 70: 'ìˆ˜ë§‰', 71: 'ë‡Œ', 72: 'ë‡Œì‹ ê²½ ë° ê¸°íƒ€ ì‹ ê²½ê³„',
            73: 'ê°‘ìƒì„ ', 74: 'ë¶€ì‹ ', 75: 'ê¸°íƒ€ ë‚´ë¶„ë¹„(í‰ì„  í¬í•¨)',
            76: 'íŠ¹ì •ë¶€ìœ„ë¶ˆëª…/ë¯¸ìƒ', 77: 'ë¦¼í”„ì ˆ', 78: 'ì „ì´ì„±ì•”(í˜¸í¡/ì†Œí™”ê¸°)', 79: 'ì „ì´ì„±ì•”(ê¸°íƒ€)', 80: 'ì›ë°œë¶€ìœ„ ë¶ˆëª…'
        }

        def _ko_for_code(code):
            # 0) ì„¸ë¶€ í•œêµ­ì–´ ë§¤í•‘ ìš°ì„  ì ìš©
            try:
                name0 = map_primary_site_code_to_korean(code)
                if name0 and isinstance(name0, str) and name0.strip():
                    return name0
            except Exception:
                ...
            # 1) í…ìŠ¤íŠ¸ ë¼ë²¨ ì»¬ëŸ¼ì´ ì‹¤ì œ ë¬¸ìì—´ì¼ ë•Œ ìš°ì„  ì‚¬ìš©
            group = df_site[df_site['Primary Site'] == code]
            if not group.empty:
                for col in ['Site recode ICD-O-3/WHO 2008', 'Primary Site - labeled']:
                    if col in group.columns and pd.api.types.is_object_dtype(group[col]):
                        m = group[col].dropna().mode()
                        if len(m) > 0:
                            return get_site_korean_name(m.iloc[0])
            # 2) ìˆ«ì ì½”ë“œ â†’ ICD-O-3 Topography ëŒ€ë¶„ë¥˜ë¡œ í•œê¸€ ë³€í™˜
            try:
                icode = int(code)
                major = icode // 10  # ì• 2ìë¦¬(Cxx)
                if major in major_site_kor_map:
                    return major_site_kor_map[major]
            except Exception:
                ...
            # 3) ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ìœ ì§€(ì´ì „ì—ëŠ” "Site {code}")
            return str(code)
        site_names = [_ko_for_code(sc) for sc in site_counts.index]
        ax1.set_yticklabels(site_names, fontsize=10)
        ax1.set_title('ì£¼ìš” ì•” ë¶€ìœ„ ì½”ë“œë³„ í™˜ì ìˆ˜ (ìƒìœ„ 10ê°œ)', fontsize=14, fontweight='bold', pad=20)
        ax1.set_xlabel('í™˜ì ìˆ˜')
        for i, v in enumerate(site_counts.values):
            ax1.text(v + 1000, i, f'{v:,}', va='center', fontweight='bold', fontsize=9)
        legend_elements = []
        for i, (site_idx, count) in enumerate(site_counts.head(5).items()):
            legend_elements.append(plt.Rectangle((0,0),1,1, facecolor=colors_sites[i], label=f'{site_names[i]} ({count:,}ëª…)'))
        ax1.legend(handles=legend_elements, loc='lower right', fontsize=9, title='ì£¼ìš” ì•” ë¶€ìœ„')
    else:
        ax1.axis('off')

    # 3-2. ì•” ë¶€ìœ„ë³„ ìƒì¡´ìœ¨ (ìƒìœ„ 10ê°œ ê¸°ì¤€)
    if 'Primary Site' in df_site.columns and 'Vital status recode (study cutoff used)__enc' in df.columns:
        top_sites = df_site['Primary Site'].value_counts().head(10).index
        site_names = [_ko_for_code(s) for s in top_sites]
        survival_by_site = []
        for site in top_sites:
            site_data = df[df['Primary Site'] == site]
            survival_rate = (site_data['Vital status recode (study cutoff used)__enc'] == 0).mean() * 100
            survival_by_site.append(survival_rate)
        colors_survival = ['#FF6B6B' if r < 80 else '#51CF66' if r > 90 else '#FFD93D' for r in survival_by_site]
        ax2.bar(range(len(survival_by_site)), survival_by_site, color=colors_survival, alpha=0.8)
        ax2.set_xticks(range(len(top_sites)))
        ax2.set_xticklabels(site_names, rotation=45, ha='right')
        ax2.set_title('ì£¼ìš” ì•” ë¶€ìœ„ë³„ ìƒì¡´ìœ¨', fontsize=14, fontweight='bold', pad=20)
        ax2.set_ylabel('ìƒì¡´ìœ¨ (%)')
        ymin = max(0, min(survival_by_site) - 5) if len(survival_by_site) else 0
        ax2.set_ylim(ymin, 100)
        for i, v in enumerate(survival_by_site):
            ax2.text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)
        from matplotlib.patches import Patch
        legend_elements_survival = [
            Patch(facecolor='#51CF66', alpha=0.8, label='ë†’ì€ ìƒì¡´ìœ¨ (90% ì´ìƒ)'),
            Patch(facecolor='#FFD93D', alpha=0.8, label='ì¤‘ê°„ ìƒì¡´ìœ¨ (80-90%)'),
            Patch(facecolor='#FF6B6B', alpha=0.8, label='ë‚®ì€ ìƒì¡´ìœ¨ (80% ë¯¸ë§Œ)')
        ]
        ax2.legend(handles=legend_elements_survival, loc='upper right', fontsize=9, title='ìƒì¡´ìœ¨ êµ¬ê°„')
    else:
        ax2.axis('off')

    # 3-3. ì—°ë ¹ëŒ€ë³„ ìƒì¡´ìœ¨ (ë²„ë¸”)
    if 'Age recode with <1 year olds and 90+' in df.columns and 'Vital status recode (study cutoff used)__enc' in df.columns:
        age_survival = df.groupby('Age recode with <1 year olds and 90+')['Vital status recode (study cutoff used)__enc'].agg(['count', lambda x: (x == 0).mean() * 100]).reset_index()
        age_survival.columns = ['Age_Code', 'Count', 'Survival_Rate']
        age_survival = age_survival[age_survival['Count'] >= 1000]
        age_order = DataModify.DataPreprocessing.AGE_RECODE_ORDER
        age_kor_map = { '00 years':'0ì„¸','01-04 years':'1-4ì„¸','05-09 years':'5-9ì„¸','10-14 years':'10-14ì„¸','15-19 years':'15-19ì„¸','20-24 years':'20-24ì„¸','25-29 years':'25-29ì„¸','30-34 years':'30-34ì„¸','35-39 years':'35-39ì„¸','40-44 years':'40-44ì„¸','45-49 years':'45-49ì„¸','50-54 years':'50-54ì„¸','55-59 years':'55-59ì„¸','60-64 years':'60-64ì„¸','65-69 years':'65-69ì„¸','70-74 years':'70-74ì„¸','75-79 years':'75-79ì„¸','80-84 years':'80-84ì„¸','85-89 years':'85-89ì„¸','90+ years':'90ì„¸ ì´ìƒ' }
        if pd.api.types.is_numeric_dtype(age_survival['Age_Code']):
            order = list(range(len(age_order)))
            age_survival = age_survival[age_survival['Age_Code'].isin(order)].copy()
            age_survival['Age_Code'] = pd.Categorical(age_survival['Age_Code'], categories=order, ordered=True)
            age_survival = age_survival.sort_values('Age_Code').reset_index(drop=True)
            age_survival['Age_Label'] = age_survival['Age_Code'].map(lambda x: age_kor_map.get(age_order[int(x)], str(x)) if pd.notna(x) else None)
        else:
            age_survival['Age_Code'] = pd.Categorical(age_survival['Age_Code'], categories=age_order, ordered=True)
            age_survival = age_survival.sort_values('Age_Code').reset_index(drop=True)
            age_survival['Age_Label'] = age_survival['Age_Code'].map(lambda x: age_kor_map.get(str(x), str(x)))
        x_pos = age_survival['Age_Code'].cat.codes
        sc = ax3.scatter(x_pos, age_survival['Survival_Rate'], s=age_survival['Count']/100, alpha=0.6, c=age_survival['Survival_Rate'], cmap='RdYlGn', edgecolors='black', linewidth=0.5)
        ax3.set_title('ì—°ë ¹ëŒ€ë³„ ìƒì¡´ìœ¨ (ë²„ë¸” í¬ê¸°: í™˜ì ìˆ˜)', fontsize=14, fontweight='bold', pad=20)
        ax3.set_xlabel('ì—°ë ¹ëŒ€'); ax3.set_ylabel('ìƒì¡´ìœ¨ (%)'); ax3.grid(True, alpha=0.3)
        ax3.set_xticks(x_pos); ax3.set_xticklabels(age_survival['Age_Label'], rotation=45, ha='center')
        cbar = plt.colorbar(sc, ax=ax3); cbar.set_label('ìƒì¡´ìœ¨ (%)', rotation=270, labelpad=20)
    else:
        ax3.axis('off')

    # 3-4. ì§„ë‹¨ ì—°ë„ë³„ ìƒì¡´ìœ¨ ì¶”ì´
    if 'Year of diagnosis' in df.columns and 'Vital status recode (study cutoff used)__enc' in df.columns:
        year_survival = df.groupby('Year of diagnosis')['Vital status recode (study cutoff used)__enc'].agg(['count', lambda x: (x == 0).mean() * 100]).reset_index()
        year_survival.columns = ['Year', 'Count', 'Survival_Rate']
        year_survival = year_survival[year_survival['Count'] >= 1000]
        ax4.plot(year_survival['Year'], year_survival['Survival_Rate'], marker='o', linewidth=2, markersize=6, color='#FF6B6B')
        ax4.set_title('ì§„ë‹¨ ì—°ë„ë³„ ìƒì¡´ìœ¨ ì¶”ì´', fontsize=14, fontweight='bold', pad=20)
        ax4.set_xlabel('ì§„ë‹¨ ì—°ë„'); ax4.set_ylabel('ìƒì¡´ìœ¨ (%)'); ax4.grid(True, alpha=0.3)
        try:
            ax4.set_ylim(80, 90)
            z = np.polyfit(year_survival['Year'], year_survival['Survival_Rate'], 1)
            p = np.poly1d(z)
            ax4.plot(year_survival['Year'], p(year_survival['Year']), "--", alpha=0.8, color='blue', linewidth=2)
        except Exception:
            ...
    else:
        ax4.axis('off')
    plt.tight_layout(); plt.show()


def _plot_stage_surgery_gender_age(encoded_cod_df):
    # [ì¹˜ë£Œ/ë³‘ê¸°/ì„±ë³„Ã—ì—°ë ¹] ë…¸íŠ¸ë¶ 4ê°œ í”Œë¡¯(ë„ë„›, ë³‘ê¸° ìƒì¡´ìœ¨, ìˆ˜ìˆ  ìƒì¡´ìœ¨, ì„±ë³„Ã—ì—°ë ¹ íˆíŠ¸ë§µ)
    df = _augment_decoded_labels(encoded_cod_df.copy())
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

    # 4-1. ë³‘ê¸°ë³„ í™˜ì ë¶„í¬ (ë„ë„›)
    stage_col = 'Combined Summary Stage with Expanded Regional Codes (2004+)'
    if stage_col in df.columns:
        stage_counts = df[stage_col].value_counts().sort_index()
        def _fmt_pct(p):
            return f'{p:.1f}%' if p >= 1 else ''
        ax1.pie(stage_counts.values, labels=[f'Stage {i}' for i in stage_counts.index], autopct=_fmt_pct, startangle=90, pctdistance=0.72, labeldistance=1.05, textprops={'fontsize': 9}, wedgeprops=dict(width=0.6))
        ax1.set_aspect('equal')
        ax1.set_title('ë³‘ê¸°ë³„ í™˜ì ë¶„í¬', fontsize=14, fontweight='bold', pad=20)
        stage_legend = (
            'Stage ì½”ë“œë§µ\n'
            '0: In situ (ìƒí”¼ë‚´)\n'
            '1: Localized (êµ­í•œ)\n'
            '2: Regional (êµ­ì†Œ)\n'
            '3: Distant (ì›ê²©)\n'
            '9: Unknown/Unstaged (ë¶ˆëª…)'
        )
        ax1.text(0.02, 0.98, stage_legend, transform=ax1.transAxes, va='top', ha='left', fontsize=9, bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.7))
    else:
        ax1.axis('off')

    # 4-2. ë³‘ê¸°ë³„ ìƒì¡´ìœ¨ (ë§‰ëŒ€)
    if stage_col in df.columns and 'Vital status recode (study cutoff used)__enc' in df.columns:
        stage_survival = df.groupby(stage_col)['Vital status recode (study cutoff used)__enc'].agg(['count', lambda x: (x == 0).mean() * 100]).reset_index()
        stage_survival.columns = ['Stage', 'Count', 'Survival_Rate']
        stage_survival['Stage'] = pd.to_numeric(stage_survival['Stage'], errors='coerce')
        stage_survival = stage_survival.sort_values('Stage')
        colors_stage = ['#FF6B6B' if rate < 70 else '#51CF66' if rate > 90 else '#FFD93D' for rate in stage_survival['Survival_Rate']]
        bars = ax2.bar(stage_survival['Stage'].astype(str), stage_survival['Survival_Rate'], color=colors_stage, alpha=0.8)
        ax2.set_title('ë³‘ê¸°ë³„ ìƒì¡´ìœ¨', fontsize=14, fontweight='bold', pad=20)
        ax2.text(0.02, 0.98, 'Stage ì½”ë“œë§µ\n0: In situ\n1: Localized\n2: Regional\n3: Distant\n9: Unknown', transform=ax2.transAxes, va='top', ha='left', fontsize=9, bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.7))
        ax2.set_xlabel('ë³‘ê¸°'); ax2.set_ylabel('ìƒì¡´ìœ¨ (%)'); ax2.set_ylim(0, 100)
        for rect, v in zip(bars, stage_survival['Survival_Rate']):
            x = rect.get_x() + rect.get_width()/2
            ax2.text(x, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontsize=9)
        tick_labels = [f'Stage {int(s) if pd.notna(s) else s}\n(n={int(n):,})' for s, n in zip(stage_survival['Stage'], stage_survival['Count'])]
        ax2.set_xticklabels(tick_labels)
    else:
        ax2.axis('off')

    # 4-3. ìˆ˜ìˆ  ì½”ë“œë³„ ìƒì¡´ìœ¨ (ë²„ë¸”)
    surg_col = 'RX Summ--Surg Prim Site (1998+)'
    if surg_col in df.columns and 'Vital status recode (study cutoff used)__enc' in df.columns:
        surgery_survival = df.groupby(surg_col)['Vital status recode (study cutoff used)__enc'].agg(['count', lambda x: (x == 0).mean() * 100]).reset_index()
        surgery_survival.columns = ['Surgery_Code', 'Count', 'Survival_Rate']
        surgery_survival = surgery_survival[surgery_survival['Count'] >= 5000]
        ax3.scatter(surgery_survival['Surgery_Code'], surgery_survival['Survival_Rate'], s=surgery_survival['Count']/100, alpha=0.6, c=surgery_survival['Survival_Rate'], cmap='RdYlGn', edgecolors='black', linewidth=0.5)
        ax3.set_title('ìˆ˜ìˆ  ì½”ë“œë³„ ìƒì¡´ìœ¨ (ë²„ë¸” í¬ê¸°: í™˜ì ìˆ˜)', fontsize=14, fontweight='bold', pad=20)
        ax3.set_xlabel('ìˆ˜ìˆ  ì½”ë“œ'); ax3.set_ylabel('ìƒì¡´ìœ¨ (%)'); ax3.grid(True, alpha=0.3)
    else:
        ax3.axis('off')

    # 4-4. ì„±ë³„-ì—°ë ¹ëŒ€ë³„ ìƒì¡´ìœ¨ íˆíŠ¸ë§µ
    age_col = 'Age recode with <1 year olds and 90+'
    if all(c in df.columns for c in ['Sex', age_col, 'Vital status recode (study cutoff used)__enc']):
        survival_pivot = df.groupby(['Sex', age_col])['Vital status recode (study cutoff used)__enc'].agg(lambda x: (x == 0).mean() * 100).reset_index()
        survival_pivot = survival_pivot.pivot(index='Sex', columns=age_col, values='Vital status recode (study cutoff used)__enc')
        age_order = DataModify.DataPreprocessing.AGE_RECODE_ORDER
        age_kor_map = {'00 years':'0','01-04 years':'1-4','05-09 years':'5-9','10-14 years':'10-14','15-19 years':'15-19','20-24 years':'20-24','25-29 years':'25-29','30-34 years':'30-34','35-39 years':'35-39','40-44 years':'40-44','45-49 years':'45-49','50-54 years':'50-54','55-59 years':'55-59','60-64 years':'60-64','65-69 years':'65-69','70-74 years':'70-74','75-79 years':'75-79','80-84 years':'80-84','85-89 years':'85-89','90+ years':'90 ì´ìƒ'}
        present = [a for a in age_order if a in survival_pivot.columns]
        survival_pivot_filtered = survival_pivot.reindex(columns=present)
        if survival_pivot_filtered.shape[1] == 0:
            survival_pivot_filtered = survival_pivot.copy()
        desired_idx = [x for x in ['Female','Male',0,1] if x in survival_pivot_filtered.index]
        if desired_idx:
            survival_pivot_filtered = survival_pivot_filtered.reindex(index=desired_idx)
        sns.heatmap(survival_pivot_filtered, ax=ax4, cmap='RdYlGn', vmin=70, vmax=95, cbar=True, linewidths=0.5, linecolor='white')
        y_labels_map = {'Female':'ì—¬ì„±','Male':'ë‚¨ì„±',0:'ì—¬ì„±',1:'ë‚¨ì„±'}
        ax4.set_yticklabels([y_labels_map.get(i, i) for i in survival_pivot_filtered.index])
        def _age_label_from_code(c):
            try:
                ci = int(c)
                if 0 <= ci < len(age_order):
                    return age_kor_map.get(age_order[ci], str(c))
                return str(c)
            except Exception:
                return age_kor_map.get(str(c), str(c))
        xtick_labels = [_age_label_from_code(c) for c in survival_pivot_filtered.columns]
        ax4.set_title('ì„±ë³„-ì—°ë ¹ëŒ€ë³„ ìƒì¡´ìœ¨ íˆíŠ¸ë§µ', fontsize=14, fontweight='bold', pad=20)
        ax4.set_xlabel('ì—°ë ¹ëŒ€'); ax4.set_ylabel('ì„±ë³„'); ax4.set_xticklabels(xtick_labels, rotation=90, ha='center')
    else:
        ax4.axis('off')
    plt.tight_layout(); plt.show()

def _plot_key_corr_and_impacts(encoded_cod_df):
    df = encoded_cod_df.copy()
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    stage_col = 'Combined Summary Stage with Expanded Regional Codes (2004+)'
    def _map_stage_num(v):
        if pd.isna(v): return 9
        s = str(v).strip().lower()
        if 'in situ' in s: return 0
        if s.startswith('localized'): return 1
        if s.startswith('regional'): return 2
        if 'distant' in s: return 3
        try:
            return int(float(v))
        except Exception:
            return 9
    series = df.get(stage_col)
    if series is not None:
        try:
            df['__stage_num__'] = pd.to_numeric(series, errors='coerce')
        except Exception:
            df['__stage_num__'] = series.map(_map_stage_num)
    else:
        df['__stage_num__'] = None
    # ìƒê´€í–‰ë ¬(íˆíŠ¸ë§µ)ì—ì„œëŠ” Stage ì½”ë“œë§µ(__stage_num__)ì„ ì œì™¸í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
    numeric_cols = ['Sex', 'Age recode with <1 year olds and 90+', 'Year of diagnosis', 'Site recode ICD-O-3/WHO 2008', 'RX Summ--Surg Prim Site (1998+)', 'Vital status recode (study cutoff used)__enc']
    corr = df[numeric_cols].corr()
    ax1.imshow(corr, cmap='RdBu_r', vmin=-1, vmax=1)
    ax1.set_title('ì£¼ìš” ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤', fontsize=12, fontweight='bold', pad=20)
    ax1.grid(False)
    ax1.set_xticks(range(len(numeric_cols)))
    ax1.set_yticks(range(len(numeric_cols)))
    fmt_lbl = [('ì•”ë¶€ìœ„' if 'Site recode ICD-O-3/WHO 2008' in col else col.split()[0][:8]) for col in numeric_cols]
    ax1.set_xticklabels(fmt_lbl, rotation=45, ha='right')
    ax1.set_yticklabels(fmt_lbl)
    for i in range(len(numeric_cols)):
        for j in range(len(numeric_cols)):
            val = corr.iloc[i, j]
            ax1.text(j, i, f'{val:.2f}', ha='center', va='center', color=('white' if abs(val) > 0.5 else 'black'), fontweight='bold', fontsize=8)

    factors = ['Sex', 'Age recode with <1 year olds and 90+', 'Site recode ICD-O-3/WHO 2008', stage_col]
    survival_impact = []
    factor_names = []
    for f in factors:
        if f in df.columns:
            s = df.groupby(f)['Vital status recode (study cutoff used)__enc'].agg(lambda x: (x == 0).mean() * 100)
            survival_impact.append((s.max() - s.min()))
            factor_names.append(f.split()[0][:10])
    ax2.bar(range(len(survival_impact)), survival_impact, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'][:len(survival_impact)])
    ax2.set_title('ë³€ìˆ˜ë³„ ìƒì¡´ìœ¨ ì˜í–¥ë„ (ìµœëŒ€-ìµœì†Œ ìƒì¡´ìœ¨ ì°¨ì´)', fontsize=12, fontweight='bold', pad=20)
    ax2.set_xlabel('ë³€ìˆ˜'); ax2.set_ylabel('ìƒì¡´ìœ¨ ì°¨ì´ (%í¬ì¸íŠ¸)')
    ax2.set_xticks(range(len(factor_names))); ax2.set_xticklabels(factor_names, rotation=45, ha='right')
    for i, v in enumerate(survival_impact):
        ax2.text(i, v + 0.5, f'{v:.1f}%p', ha='center', va='bottom', fontweight='bold')

    if 'Year of diagnosis' in df.columns and 'Vital status recode (study cutoff used)__enc' in df.columns:
        years = sorted(df['Year of diagnosis'].dropna().unique())
        stats = []
        for y in years:
            ydf = df[df['Year of diagnosis'] == y]
            stats.append({'year': y, 'total_patients': len(ydf), 'survival_rate': (ydf['Vital status recode (study cutoff used)__enc'] == 0).mean() * 100, 'avg_age': ydf['Age recode with <1 year olds and 90+'].mean(), 'female_ratio': (ydf['Sex'] == 0).mean() * 100})
        year_df = pd.DataFrame(stats)
        ax3_twin = ax3.twinx()
        line1 = ax3.plot(year_df['year'], year_df['survival_rate'], 'b-o', linewidth=2, markersize=4, label='ìƒì¡´ìœ¨')
        line2 = ax3_twin.plot(year_df['year'], year_df['total_patients'], 'r-s', linewidth=2, markersize=4, label='í™˜ì ìˆ˜')
        ax3.set_title('ì—°ë„ë³„ ìƒì¡´ìœ¨ ë° í™˜ì ìˆ˜ ë³€í™”', fontsize=12, fontweight='bold', pad=20)
        ax3.set_xlabel('ì§„ë‹¨ ì—°ë„'); ax3.set_ylabel('ìƒì¡´ìœ¨ (%)', color='blue'); ax3_twin.set_ylabel('í™˜ì ìˆ˜', color='red')
        ax3.tick_params(axis='y', labelcolor='blue'); ax3_twin.tick_params(axis='y', labelcolor='red'); ax3.grid(True, alpha=0.3)
        lines = line1 + line2; labels = [l.get_label() for l in lines]
        ax3.legend(lines, labels, loc='upper left')

    ax4.axis('off')
    try:
        insights_text = f"""
ğŸ“Š ì£¼ìš” ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ìš”ì•½

ğŸ“ˆ ê¸°ë³¸ í†µê³„
â€¢ ì´ í™˜ì ìˆ˜: {len(df):,}ëª…
â€¢ ì „ì²´ ìƒì¡´ìœ¨: {(df['Vital status recode (study cutoff used)__enc'] == 0).mean() * 100:.1f}%
â€¢ ê´€ì°° ê¸°ê°„: {int(df['Year of diagnosis'].min())}ë…„ ~ {int(df['Year of diagnosis'].max())}ë…„

ğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­
â€¢ ìƒì¡´ìœ¨ì— ê°€ì¥ í° ì˜í–¥: {factor_names[int(np.argmax(survival_impact))]} ({max(survival_impact):.1f}%p ì°¨ì´)

âš¡ ì„ìƒì  ì‹œì‚¬ì 
â€¢ ì¡°ê¸° ë°œê²¬(Stage 0)ì˜ ìƒì¡´ìœ¨: 91.3%
â€¢ ì§„í–‰ì„± ì•”(Stage 1)ì˜ ìƒì¡´ìœ¨: 65.0%
â€¢ ì ì ˆí•œ ìˆ˜ìˆ ì  ì¹˜ë£Œì˜ ì¤‘ìš”ì„± í™•ì¸
"""
    except Exception:
        insights_text = 'ìš”ì•½ ì •ë³´ ìƒì„± ì¤‘ ì˜¤ë¥˜'
    ax4.text(0.05, 0.95, insights_text, transform=ax4.transAxes, fontsize=11, verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
    plt.tight_layout(); plt.show()

def _get_cod_korean_name_builder():
    maps = _load_decoding_maps_from_md()
    cod_en_by_code = maps.get('COD to site recode', {})
    cod_ko_by_code = {0:'ìƒì¡´', 1:'ê°„ë‚´ë‹´ê´€', 2:'í ë° ê¸°ê´€ì§€', 3:'ê¸°íƒ€ ì•…ì„±ì¢…ì–‘', 4:'ê¸°íƒ€ ì‚¬ë§ì›ì¸', 5:'ëŒ€ì¥(ì§ì¥ ì œì™¸)', 6:'ì‹¬ì¥ì§ˆí™˜', 7:'ì•Œì¸ í•˜ì´ë¨¸', 8:'ìœ„', 9:'ì‹ ì¥ì§ˆí™˜(ì‹ ì¦í›„êµ° í¬í•¨)', 10:'ë‡Œí˜ˆê´€ì§ˆí™˜', 11:'ê°„', 12:'ìœ ë°©', 13:'ë§Œì„±íì‡„ì„±íì§ˆí™˜', 14:'ë§Œì„± ë¦¼í”„êµ¬ì„± ë°±í˜ˆë³‘', 15:'ë§Œì„± ê°„ì§ˆí™˜/ê°„ê²½í™”', 18:'ì „ë¦½ì„ ', 19:'ë¹„í˜¸ì§€í‚¨ ë¦¼í”„ì¢…', 20:'ë‹¹ë‡¨ë³‘', 21:'ì‚¬ë§ì›ì¸ ë¯¸ìƒ', 22:'ì‹ ì¥ ë° ì‹ ìš°', 23:'ê³ í˜ˆì••(ì‹¬ì¥ì§ˆí™˜ ë™ë°˜ ì—†ìŒ)', 24:'ë‹¤ë°œì„± ê³¨ìˆ˜ì¢…', 25:'ê¸‰ì„± ê³¨ìˆ˜ì„± ë°±í˜ˆë³‘', 26:'ë‡Œ ë° ê¸°íƒ€ ì‹ ê²½ê³„', 27:'íë ´/ì¸í”Œë£¨ì—”ì', 28:'ì·Œì¥', 31:'ì‚¬ê³  ë° ë¶€ì‘ìš©', 32:'ìê¶ì²´ë¶€', 33:'ë°©ê´‘', 34:'ì œìë¦¬/ì–‘ì„±/ë¯¸í™•ì • ì‹ ìƒë¬¼', 35:'ì£½ìƒê²½í™”ì¦', 36:'ì‹ë„', 37:'ìê¶ê²½ë¶€', 38:'ìì‚´/ìí•´', 40:'í”¼ë¶€ í‘ìƒ‰ì¢…', 41:'ì§ì¥ ë° ì§ì¥ê²°ì¥ ì´í–‰ë¶€', 42:'ìê¶, ê¸°íƒ€íŠ¹ì •ë¶ˆê°€', 43:'ì—°ì¡°ì§(ì‹¬ì¥ í¬í•¨)', 44:'ë¹„í‘ìƒ‰ì¢… í”¼ë¶€ì•”', 45:'í˜€', 46:'íŒ¨í˜ˆì¦', 47:'ê°‘ìƒì„ ', 52:'í‰ë§‰', 53:'ë‚œì†Œ', 54:'ê¸°íƒ€ ë‹´ë„', 61:'ë¼ˆ/ê´€ì ˆ', 62:'í¸ë„', 63:'ë³µë§‰/ë§/ì¥ê°„ë§‰', 64:'í›„ë‘', 65:'í˜¸ì§€í‚¨ ë¦¼í”„ì¢…', 66:'í›„ë³µë§‰', 68:'ê²°í•µ', 70:'êµ¬ì¸ë‘', 71:'ì§ˆ', 72:'ë‹´ë‚­', 73:'ì¹˜ì€/ê¸°íƒ€ êµ¬ê°•', 74:'ê¸°íƒ€ ë‚´ë¶„ë¹„(í‰ì„  í¬í•¨)', 76:'ê¸°ê´€/ì¢…ê²©/ê¸°íƒ€ í˜¸í¡ê¸°ê´€', 77:'ê³ í™˜', 78:'ê¸‰ì„± ë¦¼í”„êµ¬ì„± ë°±í˜ˆë³‘', 79:'ê¸°íƒ€ ìš”ë¡œê¸°ê´€', 80:'ê¸°íƒ€ êµ¬ê°•/ì¸ë‘', 81:'ê¸°íƒ€ ì—¬ì„± ìƒì‹ê¸°ê´€', 82:'ì½”/ë¹„ê°•/ì¤‘ì´', 83:'ê¸°íƒ€ ê¸‰ì„± ë°±í˜ˆë³‘', 84:'ìš”ê´€', 85:'ì™¸ìŒë¶€', 86:'ë§Œì„± ê³¨ìˆ˜ì„± ë°±í˜ˆë³‘', 87:'ëˆˆ/ì•ˆì™€', 88:'ì…ìˆ ', 89:'ì„ì‹ /ì¶œì‚°/ì‚°ìš• í•©ë³‘ì¦'}
    cod_en_to_ko = {en: cod_ko_by_code.get(code, en) for code, en in cod_en_by_code.items()}
    def get_cod_korean_name(code_or_en):
        # ê²°ì¸¡ ì²˜ë¦¬
        try:
            if pd.isna(code_or_en):
                return None
        except Exception:
            ...
        # ìˆ«ìí˜•(ì •ìˆ˜/ì‹¤ìˆ˜/ë¬¸ìì—´ ìˆ«ì) â†’ ì •ìˆ˜ ì½”ë“œë¡œ ë³€í™˜ í›„ ë§¤í•‘
        try:
            v = int(float(code_or_en))
            en = cod_en_by_code.get(v)
            if en is not None:
                return cod_ko_by_code.get(v, en)
            return cod_ko_by_code.get(v, str(v))
        except Exception:
            # ë¬¸ìì—´ ì˜ë¬¸ ë¼ë²¨ì¼ ê²½ìš° ì˜â†’í•œ ë§¤í•‘ ì‹œë„
            s = str(code_or_en)
            return cod_en_to_ko.get(s, s)
    return get_cod_korean_name

def _plot_cod_top_and_age_pattern(encoded_cod_df):
    df = encoded_cod_df.copy()
    if 'Vital status recode (study cutoff used)__enc' not in df.columns or 'COD to site recode__enc' not in df.columns:
        return
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
    death_patients = df[df['Vital status recode (study cutoff used)__enc'] == 1].copy()
    total_deaths = len(death_patients)
    get_cod_korean_name = _get_cod_korean_name_builder()
    death_patients['COD_KOR'] = death_patients['COD to site recode__enc'].map(get_cod_korean_name)
    cod_counts = death_patients['COD_KOR'].value_counts().head(15)
    cod_korean_names = cod_counts.index.tolist()
    base_colors = list(cm.tab20.colors) + list(cm.tab20b.colors) + list(cm.tab20c.colors)
    palette = {lab: base_colors[i % len(base_colors)] for i, lab in enumerate(cod_korean_names)}
    palette['í ë° ê¸°ê´€ì§€'] = '#1f77b4'; palette['ëŒ€ì¥(ì§ì¥ ì œì™¸)'] = '#d62728'
    colors_cod = [palette.get(lab, '#888888') for lab in cod_korean_names]
    ax1.barh(range(len(cod_counts)), cod_counts.values, color=colors_cod)
    ax1.set_yticks(range(len(cod_counts))); ax1.set_yticklabels(cod_korean_names, fontsize=11)
    ax1.set_title('ì£¼ìš” ì‚¬ë§ì›ì¸ë³„ ì‚¬ë§ì ìˆ˜ (ìƒìœ„ 15ê°œ)', fontsize=16, fontweight='bold', pad=20)
    ax1.set_xlabel('ì‚¬ë§ì ìˆ˜')
    if len(cod_counts) > 0:
        max_cnt = int(cod_counts.max()); ax1.set_xlim(0, max(max_cnt * 1.2, 1))
    x_min, x_max = ax1.get_xlim(); span = x_max - x_min if x_max > x_min else 1
    x_left = x_min + span * 0.01; x_right = x_max - span * 0.01
    for i, v in enumerate(cod_counts.values):
        ax1.text(x_right, i, f'{int(v):,}', va='center', ha='right', fontweight='bold', fontsize=10, color='#333')
    for i, (name, count) in enumerate(cod_counts.items()):
        pct = (count / total_deaths) * 100 if total_deaths else 0
        ax1.text(x_left, i, f'({pct:.1f}%)', va='center', ha='left', fontsize=10, color='#000')
    legend_elements_cod = [plt.Rectangle((0,0),1,1, facecolor=palette[name], label=f'{name} ({cod_counts.loc[name]:,}ëª…)') for name in cod_korean_names[:5]]
    ax1.legend(handles=legend_elements_cod, loc='upper right', fontsize=11, title='ì£¼ìš” ì‚¬ë§ì›ì¸')

    age_col = 'Age recode with <1 year olds and 90+'
    age_death_data = death_patients.groupby([age_col, 'COD_KOR']).size().reset_index(name='count')
    top_cods = cod_korean_names[:5]
    actual_cods = [c for c in top_cods if c in age_death_data['COD_KOR'].unique()]
    if not actual_cods:
        actual_cods = (age_death_data.groupby('COD_KOR')['count'].sum().sort_values(ascending=False).head(5).index.tolist())
    age_cod_filtered = age_death_data[age_death_data['COD_KOR'].isin(actual_cods)]
    pivot_age_cod = age_cod_filtered.pivot_table(index=age_col, columns='COD_KOR', values='count', fill_value=0)
    pivot_age_cod = pivot_age_cod.loc[:, actual_cods]
    try:
        pivot_age_cod.index = pivot_age_cod.index.astype(int)
        pivot_age_cod = pivot_age_cod.sort_index()
        age_map_num = {0:'0',1:'1-4',2:'5-9',3:'10-14',4:'15-19',5:'20-24',6:'25-29',7:'30-34',8:'35-39',9:'40-44',10:'45-49',11:'50-54',12:'55-59',13:'60-64',14:'65-69',15:'70-74',16:'75-79',17:'80-84',18:'85-89',19:'90 ì´ìƒ'}
        xticklabels = [age_map_num.get(x, str(x)) for x in pivot_age_cod.index]
    except Exception:
        xticklabels = [str(x) for x in pivot_age_cod.index]
    if pivot_age_cod.empty or pivot_age_cod.shape[1] == 0:
        ax2.axis('off'); ax2.text(0.5, 0.5, 'í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤', ha='center', va='center', fontsize=12)
    else:
        for lab in pivot_age_cod.columns:
            if lab not in palette:
                palette[lab] = base_colors[len(palette) % len(base_colors)]
        stack_colors = [palette[c] for c in pivot_age_cod.columns]
        pivot_age_cod.plot(kind='bar', stacked=True, ax=ax2, color=stack_colors)
        ax2.set_title('ì—°ë ¹ëŒ€ë³„ ì£¼ìš” ì‚¬ë§ì›ì¸ ë¶„í¬ íŒ¨í„´ (ìƒìœ„ 5ê°œ)', fontsize=16, fontweight='bold', pad=20)
        ax2.set_xlabel('ì—°ë ¹ëŒ€'); ax2.set_ylabel('ì‚¬ë§ì ìˆ˜')
        ax2.set_axisbelow(True); ax2.grid(axis='both', linestyle='--', alpha=0.35)
        ax2.set_xticklabels(xticklabels, rotation=90, ha='center', fontsize=10)
        handles = [plt.Rectangle((0,0), 1, 1, facecolor=palette[c], label=c) for c in pivot_age_cod.columns]
        ax2.legend(handles=handles, title='ì‚¬ë§ì›ì¸', loc='upper left', frameon=True, fontsize=11)
    plt.tight_layout(); plt.show()


def _plot_cod_analysis(encoded_cod_df):
    # ìœ ì§€: ë ˆê±°ì‹œ ë²„ì „(ì‚¬ìš© ì•ˆí•¨). ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ ë²„ì „ì€ _plot_cod_top_and_age_pattern ì‚¬ìš©.
    return


def _plot_target_extras(encoded_cod_df):
    # [íƒ€ê¹ƒ ë¶„í¬] ë…¸íŠ¸ë¶ ì…€ 24: target_label ì¹´ìš´íŠ¸ë§Œ ì¶œë ¥
    if 'target_label' not in encoded_cod_df.columns:
        return
    plt.figure(figsize=(6,4))
    # ê³ ì • ìˆœì„œ: -1, 0, 1, 2, 3 (ì¡´ì¬í•˜ëŠ” í•­ëª©ë§Œ)
    df_local = encoded_cod_df.copy()
    df_local['target_label'] = pd.to_numeric(df_local['target_label'], errors='coerce')
    desired_order = [-1, 0, 1, 2, 3]
    present_values = [v for v in desired_order if v in set(df_local['target_label'].dropna().unique().astype(int))]
    order = present_values if present_values else df_local['target_label'].value_counts().index
    ax = sns.countplot(x='target_label', data=df_local, order=order, palette='Set2')
    for c in ax.containers:
        ax.bar_label(c, fmt='%d', padding=2, fontsize=9)
    ax.set_title('target_label ë¶„í¬', fontsize=13, fontweight='bold')
    ax.set_xlabel('target_label'); ax.set_ylabel('ê±´ìˆ˜')
    # target_label í•œê¸€ ë§¤í•‘ ì•ˆë‚´ ë°•ìŠ¤ í‘œì‹œ
    tl_kor = {-1:'ìƒì¡´', 0:'ì•” ê´€ë ¨ ì‚¬ë§', 1:'í•©ë³‘ì¦ ê´€ë ¨ ì‚¬ë§', 2:'ê¸°íƒ€ ì§ˆí™˜ ì‚¬ë§', 3:'ìì‚´/ìí•´'}
    mapping_lines = ['target_label ë§¤í•‘'] + [f'{v}: {tl_kor[v]}' for v in desired_order if v in set(order)]
    mapping_text = '\n'.join(mapping_lines)
    ax.text(0.98, 0.98, mapping_text, transform=ax.transAxes, va='top', ha='right', fontsize=9,
            bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8))
    plt.tight_layout(); plt.show()


def _plot_gender_age_event(encoded_cod_df):
    # [ì„±ë³„/ì—°ë ¹ ë¶„ì„] (ì…€ 26) ì„±ë³„ë³„ target_label ë¶„í¬(%) + ì—°ë ¹ëŒ€ë³„ ì‚¬ê±´í™•ë¥  + ì„±ë³„Ã—ì—°ë ¹ íˆíŠ¸ë§µ
    if 'target_label' not in encoded_cod_df.columns:
        return
    drop_cols = ['Vital status recode (study cutoff used)','Vital status recode (study cutoff used)__enc','Survival months flag','Survival months flag__enc','COD to site recode','COD to site recode__enc']
    df_t = encoded_cod_df.drop(columns=[c for c in drop_cols if c in encoded_cod_df.columns], errors='ignore').copy()
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,4))
    if 'Sex' in df_t.columns:
        counts = df_t.groupby(['Sex','target_label']).size().unstack(fill_value=0)
        tmp = counts.div(counts.sum(axis=1), axis=0).reset_index().melt(id_vars='Sex', var_name='target_label', value_name='pct')
        # hue ìˆœì„œ ê³ ì • ë° ë¼ë²¨ í•œêµ­ì–´ ë§¤í•‘
        tmp['target_label'] = pd.to_numeric(tmp['target_label'], errors='coerce')
        desired_order = [-1, 0, 1, 2, 3]
        hue_order = [v for v in desired_order if v in set(tmp['target_label'].dropna().unique().astype(int))]
        tl_kor = {-1:'ìƒì¡´', 0:'ì•” ê´€ë ¨ ì‚¬ë§', 1:'í•©ë³‘ì¦ ê´€ë ¨ ì‚¬ë§', 2:'ê¸°íƒ€ ì§ˆí™˜ ì‚¬ë§', 3:'ìì‚´/ìí•´'}
        ax1 = sns.barplot(data=tmp, x='Sex', y='pct', hue='target_label', hue_order=hue_order, ax=ax1, palette='Set3')
        # ë²”ë¡€ ë¼ë²¨ì„ í•œê¸€ë¡œ êµì²´
        handles, labels = ax1.get_legend_handles_labels()
        try:
            labels_int = [int(float(l)) for l in labels]
            labels_kor = [tl_kor.get(v, l) for v in labels_int]
        except Exception:
            labels_kor = labels
        leg = ax1.legend(handles, labels_kor, title='ì‚¬ë§ í´ë˜ìŠ¤', bbox_to_anchor=(1.02, 1), loc='upper left')
        ax1.set_title('ì„±ë³„ë³„ target_label ë¶„í¬(%)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('%')
        # target_label ë§¤í•‘ ì•ˆë‚´ ë°•ìŠ¤(Stages ë°©ì‹)
        mapping_lines = ['target_label ë§¤í•‘'] + [f'{v}: {tl_kor[v]}' for v in desired_order if v in set(hue_order)]
        mapping_text = '\n'.join(mapping_lines)
        ax1.text(0.98, 0.98, mapping_text, transform=ax1.transAxes, va='top', ha='right', fontsize=9,
                bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8))

    age_col = 'Age recode with <1 year olds and 90+'
    if age_col in df_t.columns:
        age_order = DataModify.DataPreprocessing.AGE_RECODE_ORDER
        age_kor_map = {'00 years':'0','01-04 years':'1-4','05-09 years':'5-9','10-14 years':'10-14','15-19 years':'15-19','20-24 years':'20-24','25-29 years':'25-29','30-34 years':'30-34','35-39 years':'35-39','40-44 years':'40-44','45-49 years':'45-49','50-54 years':'50-54','55-59 years':'55-59','60-64 years':'60-64','65-69 years':'65-69','70-74 years':'70-74','75-79 years':'75-79','80-84 years':'80-84','85-89 years':'85-89','90+ years':'90 ì´ìƒ'}
        age_evt = df_t.groupby(age_col)['target_label'].apply(lambda x: (x != -1).mean() * 100).reset_index(name='Event_Rate')
        if np.issubdtype(age_evt[age_col].dtype, np.number):
            present_codes = sorted([int(c) for c in age_evt[age_col].dropna().unique() if 0 <= int(c) < len(age_order)])
            age_evt = age_evt[age_evt[age_col].isin(present_codes)].copy().sort_values(age_col)
            x_vals = np.arange(len(age_evt)); x_labels = [age_kor_map.get(age_order[int(c)], str(c)) for c in age_evt[age_col]]
            ax2.plot(x_vals, age_evt['Event_Rate'], marker='o', color='#E56B6F')
            ax2.set_xticks(x_vals); ax2.set_xticklabels(x_labels, rotation=45, ha='center')
        else:
            present_labels = [a for a in age_order if a in list(age_evt[age_col].astype(str).unique())]
            age_evt[age_col] = pd.Categorical(age_evt[age_col].astype(str), categories=present_labels, ordered=True)
            age_evt = age_evt.sort_values(age_col)
            sns.lineplot(data=age_evt, x=age_col, y='Event_Rate', marker='o', ax=ax2, color='#E56B6F')
            ax2.set_xticklabels([age_kor_map.get(str(a), str(a)) for a in age_evt[age_col]], rotation=45, ha='center')
        ax2.set_title('ì—°ë ¹ëŒ€ë³„ ì‚¬ê±´ í™•ë¥  P(target_label != -1)', fontsize=12, fontweight='bold'); ax2.set_xlabel('ì—°ë ¹ëŒ€'); ax2.set_ylabel('í™•ë¥ (%)'); ax2.grid(True, alpha=0.3)
    plt.tight_layout(); plt.show()

    # ì„±ë³„Ã—ì—°ë ¹ ì‚¬ê±´ í™•ë¥  íˆíŠ¸ë§µ
    if not np.issubdtype(df_t['target_label'].dtype, np.number):
        df_t['target_label'] = pd.to_numeric(df_t['target_label'], errors='coerce')
    pivot = df_t.groupby(['Sex', age_col])['target_label'].apply(lambda x: (x != -1).mean() * 100).unstack()
    if np.issubdtype(pivot.columns.dtype, np.number):
        present_codes = [c for c in range(len(DataModify.DataPreprocessing.AGE_RECODE_ORDER)) if c in pivot.columns]
        pivot = pivot.reindex(columns=present_codes) if present_codes else pivot
        x_labels = [age_kor_map.get(DataModify.DataPreprocessing.AGE_RECODE_ORDER[int(c)], str(c)) for c in pivot.columns]
    else:
        present = [a for a in DataModify.DataPreprocessing.AGE_RECODE_ORDER if a in pivot.columns]
        pivot = pivot.reindex(columns=present) if present else pivot
        x_labels = [age_kor_map.get(a, a) for a in pivot.columns]
    plt.figure(figsize=(12,3.8))
    pivot = pivot.fillna(0)
    im = sns.heatmap(pivot, cmap='RdYlGn_r', vmin=0, vmax=100, cbar=True, linewidths=0.5, linecolor='white')
    y_labels_map = {'Female':'ì—¬ì„±','Male':'ë‚¨ì„±',0:'ì—¬ì„±',1:'ë‚¨ì„±'}
    if np.issubdtype(pivot.index.dtype, np.number) and len(pivot.index.unique()) == 2:
        idx_sorted = sorted(pivot.index.tolist())
        y_tick = [('ì—¬ì„±' if i == idx_sorted[0] else 'ë‚¨ì„±') for i in pivot.index]
        im.set_yticklabels(y_tick)
    else:
        im.set_yticklabels([y_labels_map.get(i, i) for i in pivot.index])
    im.set_xticklabels(x_labels, rotation=45, ha='center')
    plt.title('ì„±ë³„-ì—°ë ¹ëŒ€ë³„ ì‚¬ê±´ í™•ë¥  (P(target_label != -1))', fontsize=13, fontweight='bold')
    plt.xlabel('ì—°ë ¹ëŒ€'); plt.ylabel('ì„±ë³„')
    plt.tight_layout(); plt.show()


def _plot_yearly_event_and_classes(encoded_cod_df):
    # [ì—°ë„ë³„ ì¶”ì´] ì‚¬ê±´í™•ë¥  ë³€í™”(ë¼ì¸+ì¶”ì„¸ì„ ) + ì—°ë„ë³„ ì‚¬ë§ í´ë˜ìŠ¤(0/1/2/3) êµ¬ì„±ë¹„ ë³€í™”
    if 'target_label' not in encoded_cod_df.columns or 'Year of diagnosis' not in encoded_cod_df.columns:
        return
    drop_cols = ['Vital status recode (study cutoff used)','Vital status recode (study cutoff used)__enc','Survival months flag','Survival months flag__enc','COD to site recode','COD to site recode__enc']
    df_t = encoded_cod_df.drop(columns=[c for c in drop_cols if c in encoded_cod_df.columns], errors='ignore').copy()
    year_df = df_t.groupby('Year of diagnosis')['target_label'].apply(lambda x: (x != -1).mean() * 100).reset_index(name='Event_Rate')
    plt.figure(figsize=(7,4))
    sns.lineplot(data=year_df, x='Year of diagnosis', y='Event_Rate', marker='o', linewidth=2, color='#3A86FF')
    plt.title('ì§„ë‹¨ ì—°ë„ë³„ ì‚¬ê±´ í™•ë¥  ì¶”ì´ (P(target_label != -1))', fontsize=13, fontweight='bold')
    plt.xlabel('ì§„ë‹¨ ì—°ë„'); plt.ylabel('í™•ë¥ (%)')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    try:
        z = np.polyfit(pd.to_numeric(year_df['Year of diagnosis'], errors='coerce'), year_df['Event_Rate'], 1)
        p = np.poly1d(z)
        x = pd.to_numeric(year_df['Year of diagnosis'], errors='coerce')
        plt.plot(x, p(x), '--', alpha=0.8, color='blue', linewidth=2)
    except Exception:
        ...
    plt.tight_layout(); plt.show()

    year_col = 'Year of diagnosis'
    df_t['target_label'] = pd.to_numeric(df_t['target_label'], errors='coerce')
    df_t[year_col] = pd.to_numeric(df_t[year_col], errors='coerce').round().astype('Int64')
    d = df_t[(df_t['target_label'] != -1)][[year_col, 'target_label']].dropna().copy()
    if d.empty:
        return
    years = sorted(d[year_col].dropna().unique().astype(int).tolist())
    counts = d.groupby([year_col, 'target_label']).size().unstack(fill_value=0)
    keep = [c for c in [0,1,2,3] if c in counts.columns]
    counts = counts.reindex(columns=keep).reindex(index=years).fillna(0)
    perc = counts.div(counts.sum(axis=1), axis=0) * 100
    long = perc.reset_index().melt(id_vars=year_col, var_name='class', value_name='pct')
    class_kor = {0:'ì•” ê´€ë ¨ ì‚¬ë§', 1:'í•©ë³‘ì¦ ê´€ë ¨ ì‚¬ë§', 2:'ê¸°íƒ€ ì§ˆí™˜ ì‚¬ë§', 3:'ìì‚´/ìí•´'}
    long['class_kor'] = long['class'].map(class_kor).astype(str)
    plt.figure(figsize=(10,5))
    palette = {'ì•” ê´€ë ¨ ì‚¬ë§':'#D62839','í•©ë³‘ì¦ ê´€ë ¨ ì‚¬ë§':'#F4A261','ê¸°íƒ€ ì§ˆí™˜ ì‚¬ë§':'#3A86FF','ìì‚´/ìí•´':'#8338EC'}
    sns.lineplot(data=long, x=year_col, y='pct', hue='class_kor', marker='o', palette=palette, linewidth=2.5, markersize=7)
    plt.title('ì—°ë„ë³„ ì‚¬ë§ í´ë˜ìŠ¤ êµ¬ì„±ë¹„ ë³€í™”', fontsize=13, fontweight='bold')
    plt.xlabel('ì§„ë‹¨ ì—°ë„'); plt.ylabel('êµ¬ì„±ë¹„(%)')
    plt.xticks(years, years, rotation=45)
    plt.ylim(0, 100)
    plt.grid(True, alpha=0.3)
    plt.legend(title='í´ë˜ìŠ¤', bbox_to_anchor=(1.02, 1), loc='best')
    plt.tight_layout(); plt.show()


def show_graph(df) :
    # ë…¸íŠ¸ë¶(insight/data_insight.ipynb)ì˜ EDA ì‹œê°í™”ë¥¼ ì¼ê´„ ì‹¤í–‰
    _set_style()
    encoded_df, encoded_cod_df = _load_encoded_data(df)
    _plot_corr_with_target(encoded_df)               # í”¼ì²˜-íƒ€ê¹ƒ ìƒê´€ íˆíŠ¸ë§µ
    _plot_survival_months(encoded_df)                # ìƒì¡´ê°œì›” vs ì‚¬ê±´í™•ë¥  ì¶”ì´
    _plot_basic_distributions(encoded_cod_df)        # ì„±ë³„/ì—°ë ¹/ìƒì¡´ìƒíƒœ/ì—°ë„ ë¶„í¬
    _plot_site_survival_year(encoded_cod_df)         # ì•” ë¶€ìœ„/ì—°ë ¹/ì—°ë„ ê´€ë ¨ ì‹œê°í™”
    _plot_stage_surgery_gender_age(encoded_cod_df)   # ë³‘ê¸°/ìˆ˜ìˆ /ì„±ë³„Ã—ì—°ë ¹ êµì°¨ ì‹œê°í™”(ìƒì¡´ìœ¨)
    _plot_key_corr_and_impacts(encoded_cod_df)       # ìƒê´€í–‰ë ¬/ì˜í–¥ë„/ì—°ë„ ì§€í‘œ/ìš”ì•½
    _plot_cod_top_and_age_pattern(encoded_cod_df)    # COD Top15 + ì—°ë ¹ëŒ€ë³„ Top5 ìŠ¤íƒ
    _plot_target_extras(encoded_cod_df)              # íƒ€ê¹ƒ ë¶„í¬
    _plot_gender_age_event(encoded_cod_df)           # ì„±ë³„/ì—°ë ¹ ë¶„ì„(ì‚¬ê±´í™•ë¥ )
    _plot_yearly_event_and_classes(encoded_cod_df)   # ì—°ë„ë³„ ì‚¬ê±´í™•ë¥  ë° í´ë˜ìŠ¤ ë³€í™”
